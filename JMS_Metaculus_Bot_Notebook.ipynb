{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joe-segal/metaculus-bot-forecaster/blob/main/JMS_Metaculus_Bot_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Forecasting Bot\n",
        "*Created by Kirill and Tom, revised by Ryan*\n",
        "\n",
        "The code below is used for making LLM-powered forecasts in Metaculus' [AI benchmarking competition](https://www.metaculus.com/project/ai-benchmarking-pilot/).\n",
        "\n",
        "Specifically, it does the following:\n",
        "\n",
        "* Gets questions from the project page using the Metaculus API\n",
        "* Gets four separate forecasts from the LLM, three independently and the fourth assessing the reasoning of the first three and producing its own.\n",
        "* Predicts on the Metaculus questions and shares a comment describing the reasoning of the fourth LLM forecast.\n",
        "\n",
        "Features and options:\n",
        "\n",
        "* Allows you to choose whether it repredicts on questions it's already forecasted on or ignores them.\n",
        "* Allows for the use of [Perplexity search](https://www.perplexity.ai/) for additional research, using a prompt formed by an LLM.\n",
        "    * *Previously this allowed for the use of pre-computed Perpelxity results, but this is no longer supported by Metaculus.*\n",
        "* Can be used with an automated workflow via Github actions to monitor the project for new open questions and make forecasts when there are some\n",
        "    * See [this Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for how to set this up"
      ],
      "metadata": {
        "id": "zMlSOSdSYCds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🚨🚨🚨 Warning 🚨🚨🚨\n",
        "\n",
        "**You are responsible for monitoring the costs of your implementation, especially if using the automated Github workflow. Cost estimates computed by this notebook are rough estimates only, make sure to check and monitor how much you are spending and the funds in your relevant accounts.**"
      ],
      "metadata": {
        "id": "TZ5X6zf7bYT-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqR47EYbh6p"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "### Make a Metaculus Bot Account\n",
        "The first step will be to make a Metaculus bot account. Instructions for how to do this have likely already been provided to you, either via a page on Metaculus or at an event.\n",
        "\n",
        "### Secrets and Tokens\n",
        "\n",
        "You need to set secrets 1) and 2) in order to make forecasts. Secrets 3) and 4) are necessary if you will be using Perplexity research.\n",
        "\n",
        "1) METACULUS_TOKEN (you can find it or create it here - https://www.metaculus.com/admin/authtoken/tokenproxy/, or ask Metaculus to share it with you).\n",
        "\n",
        "2) OPENAPI_API_KEY - (you can find it here https://platform.openai.com/settings/profile?tab=api-keys).\n",
        "\n",
        "3) PERPLEXITY_API_KEY - You can generate an API key here: https://docs.perplexity.ai/docs/getting-started\n",
        "\n",
        "These secrets can be set in your Google colab account using the key on the left side.\n",
        "\n",
        "*See the [Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for special instructions necessary for setting your secrets in Github if you intend to use the automated Github action.*\n",
        "\n",
        "*Note: previously this also used a QUESTIONS_API_KEY which got some precomputed Perplexity results stored by Metaculus, but this is no longer supported by Metaculus.*\n",
        "\n",
        "### Setting Inputs\n",
        "\n",
        "Once your tokens are set correctly, you can proceed to the [Inputs section](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=6cbruBaVtaZh). That should be the only section most users will need. More advanced users can edit the [Setup](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=tNl_mbJaX60R) and [Code](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=k8vtze4SXtR3) sections if desired, but this is not recommended unless you have coding experience."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "It is recommended that you do not edit these cells unless you have coding experience.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tNl_mbJaX60R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css(*args, **kwargs):\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "#according to this link the above wraps the output text: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results"
      ],
      "metadata": {
        "id": "girVrSlJkWUL",
        "outputId": "5bf30134-f9c6-4691-b7f1-4b0f934e592b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HifodCwcGU0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "d9823e74-43f3-4f82-b021-2af127f2e931"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.37.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import tiktoken\n",
        "import re\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "#use the below to detect if it's being run in google colab, if it's not this skips an error\n",
        "def in_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SoELZnYOGXsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7942fd1-445d-4a8c-d7f8-1f85136dfc89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading secrets from userdata (Google Colab)\n"
          ]
        }
      ],
      "source": [
        "#the below is used to get secrets when using github actions to automate\n",
        "#initialize\n",
        "metaculus_token = None\n",
        "#questions_api_key = None\n",
        "perplexity_api_key = None\n",
        "\n",
        "# Function to load secrets from the specified path\n",
        "def load_secrets(secrets_path):\n",
        "    try:\n",
        "        with open(secrets_path, 'r') as secrets_file:\n",
        "            secrets = json.loads(secrets_file.read())\n",
        "            for k, v in secrets.items():\n",
        "                os.environ[k] = v\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading secrets from {secrets_path}: {e}\")\n",
        "\n",
        "# Main code block\n",
        "try:\n",
        "    if 'secretsPath' in globals():\n",
        "        print(f\"secretsPath exists: {secretsPath}\")\n",
        "        load_secrets(secretsPath)\n",
        "\n",
        "        metaculus_token = os.environ['METACULUS_TOKEN']\n",
        "        #questions_api_key = os.environ['QUESTIONS_API_KEY']\n",
        "        perplexity_api_key = os.environ['PERPLEXITY_API_KEY']\n",
        "    else:\n",
        "        raise NameError(\"secretsPath not defined\")\n",
        "except NameError:\n",
        "    print(\"Loading secrets from userdata (Google Colab)\")\n",
        "    metaculus_token = userdata.get('METACULUS_TOKEN')\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    #questions_api_key = userdata.get('QUESTIONS_API_KEY')\n",
        "    perplexity_api_key = userdata.get('PERPLEXITY_API_KEY')\n",
        "except KeyError as e:\n",
        "    print(f\"Missing required environment variable: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs\n",
        "\n",
        "The cell below contains all of the main settings that you can change. See comments in the cell for an explanation of each. Modify them as you see fit and then run all of the cells below to forecast.\n",
        "\n",
        "*You can press Ctrl+F10 to run all of the cells after the selected one.*"
      ],
      "metadata": {
        "id": "6cbruBaVtaZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 3349  # 3129 is ID of AI Becnhmarking Pilot project. We kindly ask you not to forecast on any public tournaments or public questions in general\n",
        "MAX_QUESTIONS_TO_FORECAST = 25  # You can set it to some small number for testing or to 1_000_000 to forecast on all available questions\n",
        "REPREDICT = False # if this is false it won't predict on questions it has previously already predicted on. Set it to true to repredict on all open questions, even if it has made previous predictions.\n",
        "SUBMIT_FORECASTS = True # If set to False - forecast, but don't submit results to Metaculus platform. If set to True - forecast, and submit results to Metaculus platform\n",
        "USE_PERPLEXITY_RECENT = True # If set to true the perplexity search used is one that looks for the most recent news on the subject using a GPT prompt completion informed by the forecasting question.\n",
        "QUESTION_IDS_TO_FORECAST = None # Set to None to disable custom filtering by ID. Set to a list of IDs to only forecast on selected questions, i.e. [24191, 24190, 24189]\n",
        "#QUESTION_IDS_TO_FORECAST = [26389]\n",
        "USE_CONFIDENCE = True\n",
        "#USE_METACULUS_PROXY_ENDPOINT = False\n",
        "OPEN_AI_MODEL = 'gpt-4-turbo' # if it is one model running everything openai\n",
        "PERPLEXITY_MODEL = 'llama-3-sonar-large-32k-online'\n",
        "NUM_FORECASTS_TO_AVERAGE = 3 # 1 to go once through on the above OPEN_AI_MODEL, otherwise use MODELS_TO_RUN in sequence\n",
        "METACULUS_SUPPORTED_MODELS = ['gpt-4o']\n",
        "MODELS_TO_RUN = ['gpt-4o', 'gpt-4', 'gpt-4-turbo']\n",
        "\n",
        "# Use this to run your own question, not pulled from Metaculus\n",
        "ANSWER_MANUAL_QUESTION = False\n",
        "#manual_question = \"Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\"\n",
        "manual_question = \"Will a nuclear weapon be detonated as an act of war by Sept 30, 2024?\"\n",
        "manual_question_dict = {\n",
        "  'id': None,\n",
        "  'title': manual_question,\n",
        "  'description': manual_question,\n",
        "  'resolution_criteria': manual_question,\n",
        "  'fine_print': manual_question\n",
        "  }\n",
        "if ANSWER_MANUAL_QUESTION:\n",
        "  SUBMIT_FORECASTS = False\n",
        "\n",
        "# without confidence weighting:\n",
        "# The forecaster weights are used to produce a weighted average of the forecasts. You can adjust these weights to favor a certain forecaster/prompt more heavily.\n",
        "# Weights should sum to 1.\n",
        "forecaster1_weight = 0.2\n",
        "forecaster2_weight = 0.2\n",
        "forecaster3_weight = 0.2\n",
        "forecaster4_weight = 0.4\n",
        "\n",
        "# Prompts\n",
        "# The prompts used are below, these can be edited to hone your LLM forecasts.\n",
        "# Here is a glossary of the variables that can be inserted and used in the prompts.\n",
        "# [[title]]: This is the question text, what shows up at the top of the Metaculus question page\n",
        "# [[resolution_criteria]]: This is the resolution criteria section of the question, excluding fine print\n",
        "# [[fine_print]]: This is the fine print section of the question.\n",
        "# [[background]]: This is the background section of the resolution criteria.\n",
        "# [[today]]: The current date\n",
        "# [[forecaster1]] through {forecaster3}: These are the LLM outputs of forecasters 1 through 3, currently being used to feed into the input of forecaster 4 for it to assess in its own forecast.\n",
        "# [[summary_report]]: This is research from Perplexity. If USE_PERPLEXITY_RECENT is True, this will be the Perplexity info returned when the output of LLM_question_completion is passed to Perplexity.\n",
        "                  # If USE_PERPLEXITY_RECENT is False and ENABLE_PERPLEXITY_RESEARCH is True, it will return pre-computed Perplexity research on the question stored by Metaculus.\n",
        "                  # If both are false it will not return anything.\n",
        "\n",
        "# The LLM_question_completion prompt is used to ask the LLM what question it should ask Perplexity, if using USE_PERPLEXITY_RECENT\n",
        "prompt_template_get_perplexity_question = \"\"\"\n",
        "You're being asked the following forecasting question:\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "And it has these specific resolution details:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Fine print:\n",
        "[[fine_print]]\n",
        "\n",
        "To get the latest news that will help you forecast on the question, you need to ask your web search tool one question that would be most valuable to help you forecast\n",
        "on this question. The question should be posed so that the web search tool will provide you with the most recent information, including the latest information on the progress toward\n",
        "the criteria in the forecasting question being met. You don't want to influence it to give more negative or positive spin on the information, so make sure to phrase the question in a neutral, objective wording.  Please complete the sentence below with the most valuable question to ask:\n",
        "\n",
        "\"What is the most recent news available and prior occurrences related to the possibility of, and any indicators or evidence of. . . \"\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 1 is used by forecaster 1, with QUESTION_INFO_TEMPLATE appended to the end\n",
        "prompt_template_v1 = \"\"\"\n",
        "You are a professional forecaster interviewing for a job. The interviewer is also a professional forecaster, with a strong track record of accurate forecasts of the future.\n",
        "They will ask you a question, and your task is to provide the most accurate forecast you can. To do this, you evaluate past data and trends carefully, make use of comparison classes\n",
        "of similar events, take into account base rates about how past events unfolded, and outline the best reasons for and against any particular outcome.\n",
        "You know that great forecasters don't just forecast according to the \"vibe\" of the question and the considerations.\n",
        "Instead, they think about the question in a structured way, recording their reasoning as they go,\n",
        "and they always consider multiple perspectives that usually give different conclusions, which they reason about together.\n",
        "You can't know the future, and the interviewer knows that, so you do not need to hedge your uncertainty, you are simply trying to give\n",
        "the most accurate numbers that will be evaluated when the events later unfold.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 2 is used by forecaster 2, with QUESTION_INFO_TEMPLATE appended to the end\n",
        "prompt_template_v2 = \"\"\"\n",
        "You are a professional forecaster being tested on your skill. You are being asked a question for which you must provide the most accurate forecast you can.\n",
        "Reason step by step about the best forecast, carefully considering the information you are presented with and the potential that some of the\n",
        "background information and information provided by your research assistant may be out of date or conflicting.\n",
        "You also know that a key forecasting practice is to consider the outside view, thinking carefully about reference classes and base rates and how often similar events\n",
        "have happened in the past.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 3 is used by forecaster 3, with QUESTION_INFO_TEMPLATE appended to the end\n",
        "prompt_template_v3 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below. You have a keen eye for detail, and know that\n",
        "the resolution criteria and fine print of a question often contain important edge cases that should be considered. You also know that rookie forecasters\n",
        "tend to be underconfident, and so your forecasts should be confident and extremize some of the way toward 1% or 99%. You're also aware that forecasting questions tend\n",
        "to be biased, so when forecasting questions asks about things that would be a departure from the norm or from business as usual, those things tend not to happen.\n",
        "You will use that knowledge to make the best forecast you can, and describe your reasoning step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Forecaster 4 uses prompt 4 parts 1 and 2, with QUESTION_INFO_TEMPLATE inserted between part 1 and part 2\n",
        "final_prompt_part1 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "final_prompt_part2 = \"\"\"\n",
        "Now that you know what the question asks and some relevant background and research, your job is to make the best forecast you can. You know that examining the reasoning of other\n",
        "forecasters is an excellent way to improve your own forecast. Below I have provided the reasoning from three other forecasters who predicted on the same question.\n",
        "Examine their reasoning and use it to inform your own, using your expertise as a forecaster to assess which reasoning seems strongest and which seems flawed,\n",
        "as well as which reasoning seems to incorporate the most accurate information about base rates and historic reference classes. Construct your own reasoning and forecast,\n",
        "describing your reasoning step by step and incorporating the strongest arguments from the other forecasters in a way that improves your own reasoning. First produce a\n",
        "one sentence summary of the reasoning of each forecaster (repeating the final probability each predicted), then describe your forecast.\n",
        "\n",
        "Forecaster A:\n",
        "[[forecaster1]]\n",
        "\n",
        "Forecaster B:\n",
        "[[forecaster2]]\n",
        "\n",
        "Forecaster C:\n",
        "[[forecaster3]]\n",
        "\"\"\"\n",
        "\n",
        "# QUESTION_INFO_TEMPLATE is used with the above prompts to share the details about the question with the LLM.\n",
        "QUESTION_INFO_TEMPLATE = \"\"\"\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Here is the question's fine print that you need to be consistent with in your forecast:\n",
        "[[fine_print]]\n",
        "\n",
        "Here is some background of the question, though note that some of the details may be out of date:\n",
        "[[background]]\n",
        "\n",
        "Your research assistant provides the following information that is likely more up to date:\n",
        "[[summary_report]]\n",
        "\n",
        "Today is [[today]].\n",
        "\n",
        "Describe your reasoning step by step and give your final probability forecast in the last line of your response along with an assessment of your confidence in the accuracy of this forecast, both values as a percentage probability or confidence in exactly this form: \"Probability: XX.X% - Confidence: XX.X%\", where XX.X is a number between 0 and 100, with at most one decimal place.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "2CWVjJ9_tZ6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5575e04c-e25e-4fb0-b2a4-c9cbbedef031"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k8vtze4SXtR3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmWSCwDLbhFJ"
      },
      "source": [
        "Getting questions (only binaries)\n",
        "\n",
        "Getting them 10 at a time, you can change offset to \"scroll\" through them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "O9gVXbHIGfOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "98dad686-b59d-48ce-ae94-ab5b00b2c7db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "url = \"https://www.metaculus.com/api2/questions/\"\n",
        "\n",
        "params = {\n",
        "    \"has_group\": \"false\",\n",
        "    \"order_by\": \"-activity\",\n",
        "    \"forecast_type\": \"binary\",\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"status\": \"open\", # can change this to 'closed' for testing where you're not submitting a forecast, otherwise leave as open\n",
        "    \"type\": \"forecast\",\n",
        "    \"title-and-description-only\": \"true\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yioIDa8UsCuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e028e014-b203-444e-bded-9661b1fbcbc5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def yield_all_questions():\n",
        "  if ANSWER_MANUAL_QUESTION:\n",
        "    yield manual_question_dict\n",
        "    return\n",
        "\n",
        "  limit = 10 # This is a page limit, not question limit\n",
        "  n = 0\n",
        "  new_questions_found = False\n",
        "\n",
        "  while True:\n",
        "    offset = n * limit\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        params={**params, \"limit\": limit, \"offset\": offset},\n",
        "        headers={\"Authorization\": f\"Token {metaculus_token}\"}\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    questions = response.json().get(\"results\")\n",
        "\n",
        "    # if repredict is true it will skip to the else and predict on all the questions\n",
        "    # if repredict is false it will see if \"my_predictions\" is empty or not for each question, and only predict on questions without a prediction\n",
        "    if not REPREDICT:\n",
        "        for question in questions:\n",
        "            question_id = question['id']\n",
        "\n",
        "            guess_response = requests.get(\n",
        "                f\"{url}{question_id}/\",\n",
        "                headers={\"Authorization\": f\"Token {metaculus_token}\"}\n",
        "            )\n",
        "            guess_response.raise_for_status()\n",
        "\n",
        "            if not guess_response.json().get(\"my_predictions\"):\n",
        "                new_questions_found = True\n",
        "                yield question\n",
        "    else:\n",
        "        new_questions_found = True\n",
        "        yield from questions\n",
        "\n",
        "    if not response.json().get(\"next\"):\n",
        "      break\n",
        "    n += 1\n",
        "\n",
        "  if not new_questions_found:\n",
        "    print(\"No new questions to predict on.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dXyQLerREJGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d59177a9-3a92-4137-8134-bf0d3ec4dd37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def extract_probability(s):\n",
        "    s = s.replace(\"**\",\"\")\n",
        "    matches = re.findall(r'Probability[:\\s]+(?:\\*\\*)?[\\s]*(\\d+\\.?\\d*)%', s)\n",
        "    if matches:\n",
        "        # Return the last number found before a '%'\n",
        "        return float(matches[-1]), None\n",
        "    else:\n",
        "        # Return None if no number found\n",
        "        return None, None\n",
        "\n",
        "def extract_probability_and_confidence(s):\n",
        "    s = s.replace(\"**\",\"\")\n",
        "    # Use a regular expression to find all numbers followed by a '%'\n",
        "    matches = re.findall(r'Probability[:\\s]+(?:\\*\\*)?[\\s]*(\\d+\\.?\\d*)%', s)\n",
        "    probability = float(matches[-1])\n",
        "    matches = re.findall(r'Confidence[:\\s]+(?:\\*\\*)?[\\s]*(\\d+\\.?\\d*)%', s)\n",
        "    confidence = float(matches[-1])\n",
        "    return probability, confidence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is used to replace the {} keys with [[]], since sometimes the LLM output uses {} when formatting code.\n",
        "def replace_keys(text, key_dict, delimiter='[[', end_delimiter=']]'):\n",
        "    pattern = re.compile(re.escape(delimiter) + '(.*?)' + re.escape(end_delimiter))\n",
        "    def replace(match):\n",
        "        key = match.group(1)\n",
        "        return key_dict.get(key, match.group(0))  # Return the original if key not found\n",
        "    return pattern.sub(replace, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ldAJ5OWBW1mA",
        "outputId": "3cf08523-9a45-4a68-dbdb-7c8d3ca30a98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "EoV2KKC8l5im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dc6d3946-5006-4e92-c725-d61b992d7ad8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def predict(question_id, prediction_percentage):\n",
        "  prediction_decimal = float(prediction_percentage) / 100.0\n",
        "  url = f\"https://www.metaculus.com/api2/questions/{question_id}/predict/\"\n",
        "  response = requests.post(\n",
        "      url,\n",
        "      json={\n",
        "        \"prediction\": prediction_decimal\n",
        "      },\n",
        "      headers={\"Authorization\": f\"Token {metaculus_token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(f\"Successfully predicted {prediction_percentage}% ({prediction_decimal}) on question {question_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AJUGVfHVrms2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b397842e-035b-4fbc-fad4-bb09e2fc61ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def formulate_comment(prediction_json):\n",
        "  comment_blocks = []\n",
        "  if \"reasoning_base_rate\" in prediction_json:\n",
        "    comment_blocks.append(\"## Base rate estimation\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_base_rate\"])\n",
        "  if \"reasoning_reference_classes\" in prediction_json:\n",
        "    comment_blocks.append(\"## Reference classes\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_reference_classes\"])\n",
        "  if \"reasoning_other\" in prediction_json:\n",
        "    comment_blocks.append(\"## Additional\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_other\"])\n",
        "  return \"\\n\".join(comment_blocks) if comment_blocks else \"No reasoning provided\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7uhKwbzQsKby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "258a368f-fb28-443d-d216-8b8bfb009b3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def comment(question_id, comment_text):\n",
        "\n",
        "  # for submit_type choose \"S\" to post regular comment and \"N\" for private. Tournament submissions should be private comments.\n",
        "  url = f\"https://www.metaculus.com/api2/comments/\"\n",
        "  response = requests.post(\n",
        "    url,\n",
        "    json={\n",
        "      \"comment_text\":comment_text,\"submit_type\":\"N\",\"include_latest_prediction\":True,\"question\":question_id\n",
        "    },\n",
        "    headers={\"Authorization\": f\"Token {metaculus_token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(\"Comment Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_pricing(input, output, model):\n",
        "  encoding = tiktoken.encoding_for_model(model)\n",
        "  input_len = len(encoding.encode(input))\n",
        "  output_len = len(encoding.encode(output))\n",
        "\n",
        "  print(\"Input text is approx %s tokens.\" % input_len)\n",
        "  print(\"Output text is approx %s tokens.\" % output_len)\n",
        "\n",
        "\n",
        "  # hard coding for now, maybe make it smarter later\n",
        "  # units of $ per token\n",
        "  gpt4o_input_pricing = 5 / 1_000_000\n",
        "  gpt4o_output_pricing = 15 / 1_000_000\n",
        "\n",
        "  input_cost = input_len * gpt4o_input_pricing\n",
        "  output_cost = output_len * gpt4o_output_pricing\n",
        "  total_cost = input_cost + output_cost\n",
        "\n",
        "  return input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "THGjV1tPd_7Q",
        "outputId": "eceb98a0-5e45-4c32-b525-905e28577a51"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm(today, client, template_values, prompt_template, summary_report, model, looking_for_probability=True):\n",
        "\n",
        "  title = template_values[\"title\"]\n",
        "  resolution_criteria = template_values[\"resolution_criteria\"]\n",
        "  background = template_values[\"description\"]\n",
        "  if template_values[\"fine_print\"]:\n",
        "    fine_print = template_values[\"fine_print\"]\n",
        "  else:\n",
        "    fine_print = \"none\"\n",
        "\n",
        "  prompt_dict = {\n",
        "      \"title\": title,\n",
        "      \"summary_report\": summary_report,\n",
        "      \"today\": today,\n",
        "      \"background\": background,\n",
        "      \"fine_print\": fine_print,\n",
        "      \"resolution_criteria\": resolution_criteria,\n",
        "  }\n",
        "\n",
        "  prompt_text = replace_keys(prompt_template, prompt_dict)\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt_text\n",
        "      }\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  gpt_text = chat_completion.choices[0].message.content\n",
        "\n",
        "  #estimate cost\n",
        "  input_cost, output_cost, total_cost = estimate_pricing(prompt_text, gpt_text, model)\n",
        "\n",
        "  if looking_for_probability:\n",
        "    # Regular expression to find the number following 'Probability: '\n",
        "    try:\n",
        "      probability_match, confidence_match = extract_probability_and_confidence(gpt_text)\n",
        "    except:\n",
        "      print('Error extracting numbers from text:')\n",
        "      print(gpt_text)\n",
        "      raise ValueError\n",
        "\n",
        "    # Extract the number if a match is found\n",
        "    if probability_match:\n",
        "        probability = float(probability_match)\n",
        "    else:\n",
        "        probability = None\n",
        "        print(\"No probability found in the text! Skipping!\")\n",
        "        # Extract the number if a match is found\n",
        "    if confidence_match:\n",
        "        confidence = float(confidence_match)\n",
        "    else:\n",
        "        confidence = None\n",
        "        print(\"No confidence found in the text! Skipping!\")\n",
        "  else:\n",
        "    probability = None\n",
        "    confidence = None\n",
        "  return probability, confidence, gpt_text, input_cost, output_cost, total_cost\n",
        "\n",
        "\n",
        "def run_llm_metaculus(today, template_values, prompt_template, summary_report, model, looking_for_probability=True):\n",
        "\n",
        "  title = template_values[\"title\"]\n",
        "  resolution_criteria = template_values[\"resolution_criteria\"]\n",
        "  background = template_values[\"description\"]\n",
        "  if template_values[\"fine_print\"]:\n",
        "    fine_print = template_values[\"fine_print\"]\n",
        "  else:\n",
        "    fine_print = \"none\"\n",
        "\n",
        "  prompt_dict = {\n",
        "      \"title\": title,\n",
        "      \"summary_report\": summary_report,\n",
        "      \"today\": today,\n",
        "      \"background\": background,\n",
        "      \"fine_print\": fine_print,\n",
        "      \"resolution_criteria\": resolution_criteria,\n",
        "  }\n",
        "\n",
        "  prompt_text = replace_keys(prompt_template, prompt_dict)\n",
        "\n",
        "  url = \"https://www.metaculus.com/proxy/openai/v1/chat/completions\"\n",
        "  auth_token = metaculus_token\n",
        "\n",
        "  # Define the payload as a dictionary\n",
        "  payload = {\n",
        "      \"model\": model,\n",
        "      \"messages\": [\n",
        "          { \"role\": \"user\", \"content\": prompt_text },\n",
        "      ]\n",
        "  }\n",
        "\n",
        "  # Set the headers\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Token {auth_token}\"\n",
        "  }\n",
        "\n",
        "  # Make the POST request\n",
        "  response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      print(\"Request was successful!\")\n",
        "\n",
        "      # Parse the response JSON\n",
        "      result = response.json()\n",
        "\n",
        "      # Extract the desired text\n",
        "      gpt_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "  else:\n",
        "      print(f\"Request failed with status code: {response.status_code}\")\n",
        "      print(response.text)\n",
        "      raise ValueError\n",
        "\n",
        "  #estimate cost\n",
        "  input_cost, output_cost, total_cost = estimate_pricing(prompt_text, gpt_text, model)\n",
        "\n",
        "  if looking_for_probability:\n",
        "    # Regular expression to find the number following 'Probability: '\n",
        "    try:\n",
        "      probability_match, confidence_match = extract_probability_and_confidence(gpt_text)\n",
        "    except:\n",
        "      print('Error extracting numbers from text:')\n",
        "      print(gpt_text)\n",
        "      raise ValueError\n",
        "\n",
        "    # Extract the number if a match is found\n",
        "    if probability_match:\n",
        "        probability = float(probability_match)\n",
        "    else:\n",
        "        probability = None\n",
        "        print(\"No probability found in the text! Skipping!\")\n",
        "        # Extract the number if a match is found\n",
        "    if confidence_match:\n",
        "        confidence = float(confidence_match)\n",
        "    else:\n",
        "        confidence = None\n",
        "        print(\"No confidence found in the text! Skipping!\")\n",
        "  else:\n",
        "    probability = None\n",
        "    confidence = None\n",
        "  return probability, confidence, gpt_text, input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XK4FbnKJb98Q",
        "outputId": "8ca4217a-b896-48c7-e457-d428644a00cf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_perplexity(perplexity_prompt, perplexity_api_key):\n",
        "\n",
        "  from openai import OpenAI\n",
        "\n",
        "  YOUR_API_KEY = perplexity_api_key\n",
        "\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": (\n",
        "              \"You are an artificial intelligence assistant and you need to \"\n",
        "              \"engage in a helpful, detailed, polite conversation with a user.  \"\n",
        "              \"Please supply relevant objective and balanced information and status regarding the following questions the user will pose to you.  \"\n",
        "              \"You may also supply expert opinions (and cite the source of) if you find some that you think are important to include, \"\n",
        "              \"but you are not to editorialize very much yourself about this information.  \"\n",
        "              \"You are supporting an analysis team who are already experts in this area, \"\n",
        "              \"but need to get a quick yet thorough update on any recent news developments and the overall current status of any key factors relating to this question.  \"\n",
        "              \"Questions will usually be stated in terms something that WILL happen, or that something WILL NOT happen - either way it is asked, be sure to provide recent information on why the event or condition MAY happen and why it MAY NOT happen.\"\n",
        "          ),\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": (\n",
        "              perplexity_prompt\n",
        "          ),\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  perplexity_client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
        "\n",
        "  response = perplexity_client.chat.completions.create(\n",
        "      model=PERPLEXITY_MODEL,\n",
        "      messages=messages,\n",
        "  )\n",
        "\n",
        "  content = response.choices[0].message.content\n",
        "\n",
        "  print(\"Generated research from perplexity:\")\n",
        "  print(content)\n",
        "  print(\"\")\n",
        "\n",
        "  # get token and cost estimate\n",
        "\n",
        "  # currently using the GPT tokenizer with a 1.3 multiplier. Hacky and wrong, but rough estimate.\n",
        "  # See here for 1.3 factor estimate source: https://github.com/continuedev/continue/issues/878\n",
        "\n",
        "  perplexity_token_pricing = 1/1_000_000\n",
        "  perplexity_cost_fixed = 5/1_000\n",
        "\n",
        "  multiplier = 1.3\n",
        "  encoding = tiktoken.encoding_for_model(OPEN_AI_MODEL)\n",
        "  input_text = perplexity_prompt\n",
        "  output_text = content\n",
        "  input_len = len(encoding.encode(input_text)) * multiplier\n",
        "  output_len = len(encoding.encode(output_text)) * multiplier\n",
        "\n",
        "  input_cost = input_len * perplexity_token_pricing\n",
        "  output_cost = output_len * perplexity_token_pricing\n",
        "  fixed_cost = perplexity_cost_fixed\n",
        "  total_cost = input_cost + output_cost + perplexity_cost_fixed\n",
        "\n",
        "  print(f\"Total perplexity call cost: ${total_cost}\")\n",
        "  print(\"\")\n",
        "\n",
        "  return content, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gWXOgDDWx7il",
        "outputId": "272d30c6-e67f-4bf7-8ef8-e7d6f3a46ebf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W-wVKhWomV2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2f99a81c-a2cc-4036-f878-c51a0e2ca76f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def clean_gpt_turbo_markdown(text: str) -> str:\n",
        "  match = re.search(r\"```[\\w]+\\s+(.*?)\\s+```\", text, re.DOTALL)\n",
        "  if match:\n",
        "    cleaned_text = match.group(1).strip()\n",
        "  else:\n",
        "    cleaned_text = text\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwc6I64ScFUz"
      },
      "source": [
        "Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3C52dUgSG6Pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0edbecbd-851d-4032-acd0-5f95126fc068"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Forecasting Question:\n",
            "26389 Will the Federal Reserve cut interest rates before September 30, 2024?\n",
            "\n",
            "Run 1\n",
            "\n",
            "Using Metaculus endpoint for model: gpt-4o\n",
            "Getting Perplexity recent data...\n",
            "\n",
            "Request was successful!\n",
            "Input text is approx 368 tokens.\n",
            "Output text is approx 38 tokens.\n",
            "The completed question posed to perplexity reads: \"What is the most recent news available and prior occurrences related to the possibility of, and any indicators or evidence of, the Federal Reserve cutting interest rates before September 30, 2024?\"  Today's date is 2024-07-23.\n",
            "Generated research from perplexity:\n",
            "The most recent news available and prior occurrences related to the possibility of the Federal Reserve cutting interest rates before September 30, 2024, are as follows:\n",
            "\n",
            "1. **Recent Job Market Data**:\n",
            "   - The U.S. job market has shown signs of cooling, with the unemployment rate rising to 4.1% in June and average monthly payroll growth falling short of the 200,000 mark needed to match population growth.\n",
            "   - This slowdown could boost the confidence of Federal Reserve policymakers in their battle against inflation, potentially leading to discussions on interest-rate reductions at their upcoming gathering.\n",
            "\n",
            "2. **Federal Reserve Policy**:\n",
            "   - The Federal Reserve is not expected to alter its rate from the 5.25%-5.5% range at the end of July, but the recent data and indications of a cooling inflation and a decelerating economy might set the stage for a rate cut at the subsequent meeting.\n",
            "   - Fed Chair Jerome Powell emphasized the importance of being confident in inflation moving towards the 2% target before considering rate cuts, and any unexpected deterioration in the labor market could also prompt a rate cut.\n",
            "\n",
            "3. **Expert Opinions**:\n",
            "   - Ubeela Farqi, Chief Economist at High Economics, mentioned that the Federal Reserve could initiate discussions on rate cuts during the upcoming FOMC meeting and potentially decrease the policy rate in September if the trend of moderation persists.\n",
            "   - Top Federal Reserve officials, including John Williams, have suggested that a rate cut could be warranted in the coming months, given the improved inflation situation.\n",
            "\n",
            "4. **Market Expectations**:\n",
            "   - Market expectations are leaning towards a rate cut in September, with a probability of around 72% following the June employment report. Traders are even factoring in a second rate cut by December.\n",
            "   - Some experts argue that the Fed should cut rates now, rather than waiting until September, citing the need to support the economy in the face of rising unemployment risks.\n",
            "\n",
            "5. **Prior Meetings and Projections**:\n",
            "   - The Federal Reserve left rates unchanged in June, projecting fewer cuts for 2024. Despite modest improvements in inflation, analysts foresee the Fed retaining a cautious stance on rate cuts, keeping the benchmark policy rate within the 5.25%-5.5% range set last year.\n",
            "   - The Fed's preferred inflation gauge, the personal consumption expenditures price index, has shown a gradual decline, indicating a positive trend in inflation control efforts.\n",
            "\n",
            "Overall, while there are signs of a cooling job market and improved inflation, the Federal Reserve remains cautious about committing to immediate rate cuts. The upcoming consumer price index report and further economic data will likely influence the Fed's decision on interest rates before September 30, 2024.\n",
            "\n",
            "Total perplexity call cost: $0.005782600000000001\n",
            "\n",
            "Running initial prompt 1\n",
            "Request was successful!\n",
            "Input text is approx 1239 tokens.\n",
            "Output text is approx 698 tokens.\n",
            "Output Reasoning:\n",
            "### Step-by-Step Reasoning\n",
            "\n",
            "#### Step 1: Review Historical Context\n",
            "\n",
            "Historically, the Federal Reserve has altered the federal funds rate in response to significant economic indicators such as inflation, employment rates, and economic growth or contraction. Recent historical trends, including the rate cuts in 2020 and 2019, suggest that the Fed is willing to reduce rates during periods of economic downturn or significant uncertainty.\n",
            "\n",
            "#### Step 2: Economic Indicators Analysis\n",
            "\n",
            "1. **Employment Data**: \n",
            "   - The rising unemployment rate (4.1%) and a slowdown in average monthly payroll growth are clear signs of a cooling job market. This generally pressures the Fed to consider rate cuts to stimulate job growth.\n",
            "   - Base rate consideration: Historically, rising unemployment rates and decelerating payroll growth have correlated strongly with rate cuts.\n",
            "\n",
            "2. **Inflation Trends**:\n",
            "   - Inflation appears to be cooling, with indications that it may be moving toward the Fed's 2% target. This trend would support the decision to consider a rate cut.\n",
            "   - The Federal Reserve has consistently stated that its rate decisions are highly dependent on inflation trends.\n",
            "\n",
            "3. **Federal Reserve Policy Statements**:\n",
            "   - Fed Chair Powell and other officials have indicated a cautious stance, requiring strong confidence in economic signals before making any rate decisions. They have emphasized waiting for clear signs of sustained progress toward inflation targets.\n",
            "   - The statements from high-ranking Fed officials need to be weighted heavily, as they provide insights into possible future actions.\n",
            "\n",
            "#### Step 3: Expert Opinions and Market Expectations\n",
            "\n",
            "1. **Expert Consensus**:\n",
            "   - Economists like Ubeela Farqi suggest that discussions on rate cuts could be initiated soon, possibly leading to a rate cut in September. Such expert opinions provide significant weight as they are based on detailed economic analyses.\n",
            "\n",
            "2. **Market Expectations**:\n",
            "   - The market currently assigns a high probability (72%) to a rate cut by September, reflecting collective investor sentiment and interpretation of economic trends.\n",
            "   - Trader behavior often anticipates central bank actions, especially in response to macroeconomic indicators and Fed statements.\n",
            "\n",
            "#### Step 4: Timing and Calendar Consideration\n",
            "\n",
            "1. **FOMC Meeting Schedule**:\n",
            "   - The FOMC's scheduled meeting on September 18th provides a critical juncture for any potential announcement.\n",
            "   - If economic conditions continue to follow current trends, this meeting is a plausible timing for an announcement of a rate cut.\n",
            "\n",
            "#### Step 5: Evaluation Against Historical and Base Rates\n",
            "\n",
            "- Comparing current economic conditions to similar periods in the past where the Fed has cut rates provides a cautionary scenario. The Fed historically shifts policy stance after observing sustained trends rather than reacting to short-term data.\n",
            "- Given the recent history of rate stasis and slow rate cut projections for 2024, the probability of a rate cut, while notable, must still account for the Fed's cautious stance.\n",
            "\n",
            "### Final Probability Forecast and Confidence\n",
            "\n",
            "**Probability**: Given the current data, historical context, expert opinions, and the market's high expectation of a rate cut, the probability baseline is significant. However, factoring in the Fed’s typically cautious nature and the historical need for sustained trends before making cuts, the final estimate is:\n",
            "\n",
            "**Probability: 65.0%**\n",
            "\n",
            "**Confidence**: Given the structured analysis, historical data, and consideration of diverse perspectives and their counterarguments, the confidence in this probability forecast is high:\n",
            "\n",
            "**Confidence: 85.0%**\n",
            "\n",
            "Extracted probability percentage value (0-100): 65.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 2\n",
            "Request was successful!\n",
            "Input text is approx 1146 tokens.\n",
            "Output text is approx 627 tokens.\n",
            "Output Reasoning:\n",
            "### Step-by-Step Reasoning\n",
            "\n",
            "1. **Understanding the Question**: The question asks if the Federal Reserve (FOMC) will announce a rate cut before September 30, 2024. The announcement date is critical, not the effective date of the rate cut.\n",
            "\n",
            "2. **Examining Historical Context**:\n",
            "   - Historically, the Fed responds to economic conditions by adjusting the federal funds rate. Recent historical rate cuts were in March 2020 and during 2019, primarily in response to economic weakening or inflation control.\n",
            "   - Typically, rate cuts are considered when there are signs of economic slowdown or when inflation is under control.\n",
            "\n",
            "3. **Analyzing Current Economic Indicators**:\n",
            "   - **Job Market**: The job market shows signs of cooling, with rising unemployment (4.1%) and lower payroll growth. This could indicate an economic slowdown.\n",
            "   - **Inflation**: There are indications that inflation is cooling, which might reduce the need for high interest rates.\n",
            "   - **Overall Economic Growth**: Cooling economic growth supports the notion that the Fed might consider rate cuts to stimulate the economy.\n",
            "\n",
            "4. **Federal Reserve Policy and Statements**:\n",
            "   - Fed Chair Jerome Powell emphasized that confidence in achieving the 2% inflation target is crucial before considering rate cuts.\n",
            "   - Recent statements from top officials suggest a willingness to discuss rate cuts if inflation and economic conditions continue to moderate.\n",
            "\n",
            "5. **Expert Opinions and Market Expectations**:\n",
            "   - Several experts and market participants are anticipating a possible rate cut. Market data shows a 72% probability of a rate cut by September.\n",
            "   - Expert opinions are mixed but lean towards the possibility of at least one rate cut by September if current trends persist.\n",
            "\n",
            "6. **Upcoming Fed Meeting**:\n",
            "   - The next significant FOMC meeting is scheduled for September 18, 2024, which is the last meeting before the September 30 deadline. This will be a key moment for any potential rate cut announcements.\n",
            "\n",
            "7. **Prior Meetings and Fed Caution**:\n",
            "   - The Fed has been cautious, leaving rates unchanged in June but projecting fewer cuts for 2024. This reflects their preference for a cautious approach.\n",
            "   - The Fed's preferred inflation gauge is improving, which might give the Fed more room to consider rate cuts, but they remain cautious.\n",
            "\n",
            "### Probability Calculation\n",
            "\n",
            "Given the above analysis:\n",
            "\n",
            "- **Historical Context and Job Market**: Cooling conditions suggest a likelihood but not certainty.\n",
            "- **Federal Reserve Statements**: Despite cautious statements, they're open to discussions based on upcoming data.\n",
            "- **Market Expectations**: A high probability (72%) from market participants offers a strong indication, but markets can be wrong.\n",
            "- **Upcoming Meeting and Timing**: The September meeting is crucial and offers a realistic opportunity for an announcement.\n",
            "\n",
            "Balancing optimism from market expectations and expert opinions against the Fed's cautious approach and the conditional nature of economic improvements, I would put the probability of the Fed announcing a rate cut before September 30, 2024, at:\n",
            "\n",
            "**Probability: 65.0% - Confidence: 75.0%**\n",
            "\n",
            "Extracted probability percentage value (0-100): 65.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 3\n",
            "Request was successful!\n",
            "Input text is approx 1188 tokens.\n",
            "Output text is approx 632 tokens.\n",
            "Output Reasoning:\n",
            "### Step-by-Step Reasoning:\n",
            "\n",
            "1. **Historical Context**:\n",
            "   - Historically, the Federal Reserve has been cautious about changing the federal funds rate unless there are compelling economic reasons. The last rate cuts were in March 2020, in response to the COVID-19 pandemic. With the most recent rate cuts being four years ago, this creates a baseline expectation that rate cuts are not very frequent.\n",
            "\n",
            "2. **Current Economic Conditions**:\n",
            "   - **Job Market**: The unemployment rate has risen to 4.1%, and payroll growth is below needed levels. This indicates a cooling job market, which could theoretically persuade the Fed towards rate cuts to support employment.\n",
            "   - **Inflation**: There are signs of cooling inflation and a decelerating economy. The Fed's actions are generally very responsive to inflation trends, and a clear pathway towards achieving their inflation target would be influential.\n",
            "   - **Fed Chair's Statements**: Jerome Powell and other Fed officials have expressed the need for confidence in inflation moving towards the 2% target before reducing rates. While there are signs of improving inflation, confidence appears to be cautious.\n",
            "\n",
            "3. **Federal Reserve Policy and Meetings**:\n",
            "   - The Fed has maintained the 5.25%-5.5% range recently and continues to project fewer cuts in 2024.\n",
            "   - The next significant meeting is on September 18, 2024. This leaves a narrow window for a decision to be made before the question's deadline.\n",
            "\n",
            "4. **Market Expectations and Expert Opinions**:\n",
            "   - Market probabilities imply a 72% chance of a rate cut in September based on June's employment report.\n",
            "   - Some experts advocate for immediate cuts, although this is debated given rising unemployment risks and economic conditions.\n",
            "\n",
            "5. **Bias Consideration**:\n",
            "   - Given the tendency of forecasting questions to be biased—specifically, that departures from the norm (such as rate cuts) tend not to happen—it leans towards anticipating the status quo.\n",
            "   - Therefore, even with market-based probabilities suggesting a 72% likelihood, a more cautious stance considering historical conservatism might adjust this expectation downward.\n",
            "\n",
            "6. **Evaluation of Recent Trends and Fine Print**:\n",
            "   - Resolution criteria emphasize any announcement of a rate cut before September 30, 2024. Given the tightening timeframe and historical context, any delay could make a significant impact.\n",
            "   - Recent data suggests the possibility is non-negligible but also acknowledges that many indicators are trending only moderately towards such actions.\n",
            "\n",
            "### Probability Assessment:\n",
            "\n",
            "- With the unemployment rate rising and inflation data showing positive trends, there is clear potential for the Fed to consider rate cuts.\n",
            "- The market's expectations and expert opinions bolster this potential.\n",
            "- However, the Fed's historical caution and the general forecasting bias towards maintaining the status quo suggest moderating initial probabilities.\n",
            "\n",
            "### Final Forecast and Confidence:\n",
            "\n",
            "**Probability: 62.5% - Confidence: 90.0%**\n",
            "\n",
            "- This probability reflects a significant but moderated chance considering the convergence of economic indicators and the naturally cautious approach of the Federal Reserve. The confidence level denotes high certainty in having considered substantial variables accurately.\n",
            "\n",
            "Extracted probability percentage value (0-100): 62.5\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "+++++++++++ FINAL PROMPT (4) +++++++++++++++++\n",
            "Running final prompt...\n",
            "Request was successful!\n",
            "Input text is approx 1188 tokens.\n",
            "Output text is approx 705 tokens.\n",
            "\n",
            "Final prompt's individual (non-weighted) extracted probability percentage value (0-100): 70.0\n",
            "\n",
            "Rationale to submit:\n",
            "\n",
            "\n",
            "    *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
            "\n",
            "    * *Main LLM Model used: gpt-4o*\n",
            "    * *Weighted formula: (0.2024)(65.0% [Forecaster A]) + (0.1786)(65.0% [Forecaster B]) + (0.2143)(62.5% [Forecaster C]) + (0.4048)(70.0% [Summary Forecaster])*\n",
            "    * *** FINAL WEIGHTED FORECAST: 66.5%***\n",
            "\n",
            "    ---\n",
            "\n",
            "    \n",
            "\n",
            "Successfully predicted 66.5% (0.665) on question 26389\n",
            "Comment Success!\n",
            "Output Reasoning:\n",
            "To produce an accurate forecast, I'll take a systematic approach to analyze the information available, considering key factors influencing the Federal Reserve's decision-making process. \n",
            "\n",
            "### Step-by-Step Reasoning\n",
            "\n",
            "1. **Current Economic Indicators and Federal Reserve's Policy Goals:**\n",
            "   - **Unemployment Rate and Job Market:** The recent increase in the unemployment rate to 4.1% and falling payroll growth suggests a cooling labor market. This could influence the Fed to consider rate cuts if they anticipate the slowdown to affect overall economic stability.\n",
            "   - **Inflation Rates:** Fed Chair Jerome Powell emphasized the importance of moving towards the 2% inflation target before reducing rates. Given the personal consumption expenditures price index shows a gradual decline, the trend appears positive for inflation control.\n",
            "\n",
            "2. **Federal Reserve Current Stance and Statements:**\n",
            "   - **Current Rate Range (5.25%-5.5%):** The Fed’s decision at the end of July is not expected to change this rate. However, subsequent meetings, such as the September FOMC meeting, might consider a different approach based on emerging data.\n",
            "   - **Fed Leadership Statements:** Statements from key officials like John Williams suggest potential rate cuts if the improved inflation situation persists. This provides support for considering a rate cut as plausible, but not guaranteed.\n",
            "\n",
            "3. **Expert and Market Expectations:**\n",
            "   - **Market Sentiment:** Market expectations indicate a 72% probability for a rate cut in September following labor market data. Expectations also include the possibility of a second cut by December. These probabilities reflect market sentiment which can influence Fed considerations, but should be weighed with caution.\n",
            "   - **Expert Opinions:** Economists, like Ubeela Farqi, are considering the potential for discussions about rate cuts if trends continue. Analysts’ forecasts of Fed actions are based on interpreting data trends and inherent caution in recalibrating rates too soon.\n",
            "\n",
            "4. **Historical Context:**\n",
            "   - **Rate Cut Patterns:** The Fed last cut rates in 2020, in response to significant economic disruptions. The current economic conditions are less severe, and thus, the urgency seen in 2020 is different. The slow and cautious approach seen in 2019 reflects the Fed's preference for gradual policy adjustments.\n",
            "\n",
            "5. **Fed's Primary Concerns and Future Economic Releases:**\n",
            "   - **Cautious Approach:** The Fed has historically been cautious, especially when the forward outlook is uncertain, focusing on data-driven decisions. With key economic data being released periodically, including the consumer price index and job market reports, upcoming data will be critical in guiding the Fed's decisions. \n",
            "\n",
            "6. **Resolution Criteria:**\n",
            "   - **Timing of Announcement:** As the question resolves based on the announcement by September 30, not the effective date, the decision dynamics within upcoming FOMC meetings are crucial to watch. Fed policymakers may want to align any cut announcements with favorable data trends confirming sustained improvements.\n",
            "\n",
            "### Probability and Confidence\n",
            "\n",
            "Given the confluence of slightly cooling economic indicators, a general trend towards inflation control, cautious Fed communication, and expert/market inclinations pointing towards possible rate cuts, I would lean towards believing a rate cut could happen before September 30, 2024. \n",
            "\n",
            "However, considering historical caution, the inherent conservativism of the Fed, and the need for sustained data confirmation, I weigh towards a level of skepticism about an imminent cut versus upheld caution into late 2024.\n",
            "\n",
            "**Probability: 70.0% - Confidence: 85.0%**\n",
            "\n",
            "FINAL WEIGHTED FORECAST:\n",
            "66.5%\n",
            "\n",
            "Overall cost was: $0.06373500000000001\n",
            "\n",
            "################ NEXT QUESTION #################\n",
            "\n",
            "Now Forecasting Question:\n",
            "26389 Will the Federal Reserve cut interest rates before September 30, 2024?\n",
            "\n",
            "Run 2\n",
            "\n",
            "Using OpenAI endpoint for model: gpt-4\n",
            "Getting Perplexity recent data...\n",
            "\n",
            "Input text is approx 367 tokens.\n",
            "Output text is approx 19 tokens.\n",
            "The completed question posed to perplexity reads: What is the most recent news available and prior occurrences related to the possibility of, and any indicators or evidence of \"the Federal Reserve reducing the target federal funds rate before September 30, 2024?\"  Today's date is 2024-07-23.\n",
            "Generated research from perplexity:\n",
            "The Federal Reserve has maintained its target federal funds rate at 5.25% to 5.50% since July 2023. The most recent news and prior occurrences related to the possibility of reducing the target federal funds rate before September 30, 2024, are as follows:\n",
            "\n",
            "1. **Fed's June 2024 Meeting**: The Federal Reserve left its benchmark interest rate unchanged and projected only one rate cut in 2024, indicating a cautious approach due to persistent inflation above the 2% target.\n",
            "\n",
            "2. **Monetary Policy Report (July 2024)**: The Federal Open Market Committee (FOMC) emphasized the need for sustained improvements in inflation data before considering rate cuts. The Committee does not expect to reduce the target range until it has gained greater confidence that inflation is moving sustainably toward 2%.\n",
            "\n",
            "3. **Expert Opinions**: Some experts argue that the Fed should cut rates now rather than waiting until September, citing the need to support the economy in the face of rising unemployment risks. Others predict that the Fed will deliver hefty cuts over the next two to three years, bringing the federal-funds rate to 1.75% to 2.00% by year-end 2026.\n",
            "\n",
            "4. **Economic Indicators**: Inflation has shown modest improvements, with the personal consumption expenditures price index (PCE) gradually declining. Job gains have been strong, and the unemployment rate remains low. Real gross domestic product (GDP) growth was modest in the first quarter, while growth in private domestic demand remained robust.\n",
            "\n",
            "5. **Balance Sheet Policy**: The Federal Reserve has continued to reduce its holdings of Treasury and agency securities in a predictable manner, aiming to maintain securities holdings at amounts consistent with implementing monetary policy efficiently and effectively in its ample-reserves regime.\n",
            "\n",
            "Overall, while there are indications of a possible rate cut, the Federal Reserve remains cautious and committed to achieving its inflation target before making any adjustments to the target federal funds rate.\n",
            "\n",
            "Total perplexity call cost: $0.0055889\n",
            "\n",
            "Running initial prompt 1\n",
            "Input text is approx 1089 tokens.\n",
            "Output text is approx 450 tokens.\n",
            "Output Reasoning:\n",
            "Given the information and the present economic state, it seems that the Federal Reserve is presently inclined towards stabilizing inflation rates before considering any cuts to the target federal funds rate. The inflation, job growth, and GDP data seem to underscore a relatively healthy economy, which in ordinary circumstances would not necessitate a change in the federal funds rate. \n",
            "\n",
            "Presently, the Fed is on a cautious footing, evidenced by their unchanging benchmark rate and singularly projected cut for 2024, amid potentially destabilizing inflation rates above the 2% target. This measured approach tallies with the Monetary Policy Report of July 2024, where it is clear that the Fed is seeking greater confidence in inflation numbers before any rate reductions are considered.\n",
            "\n",
            "While some experts suggest immediate cuts to head off rising unemployment risks, it's important to remember that the unemployment rate, at present, is low with robust job growth rates. \n",
            "\n",
            "My review of historical trends shows that the Fed has rarely cut rates multiple times in short periods unless faced with significant economic constraints like recessions. In this instance, none of those constraints seem imminent. \n",
            "\n",
            "However, predictions about hefty rate cuts in the next few years suggest that the Fed may start this process before September 2024. At the moment, it's hard to be certain that these predictions will translate to action within the given timeframe. \n",
            "\n",
            "The likelihood of a rate cut in an election year (2024 being one such year) seems less probable given the historical reluctance of the Federal Reserve to influence financial markets directly preceding an election and invite political scrutiny, although this is not a binding rule. \n",
            "\n",
            "Also considering the time until the end of September 2024, there are 9 more FOMC meetings. Each of these represents a chance for the decision to be made to reduce the rate. \n",
            "\n",
            "Taking all these factors into account, there are potential reasons both for and against a rate cut before September 30, 2024. However, given the Fed's current cautious approach, strong job growth, the generally stable economy, and the historical reluctance for rate cuts in election years, my forecast leans towards a relatively lower probability of a rate cut during this period.\n",
            "\n",
            "Probability: 27.5% - Confidence: 85.0%\n",
            "\n",
            "Extracted probability percentage value (0-100): 27.5\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 2\n",
            "Input text is approx 994 tokens.\n",
            "Output text is approx 416 tokens.\n",
            "Output Reasoning:\n",
            "To make this judgment, various factors need to be considered in conjunction with historical patterns, the current economic scenario, and proposed plans.\n",
            "\n",
            "According to the historical Federal Reserve's target funds rate history page, the Fed has cut rates before. The most recent being in March 3rd and 16th 2020 while there were three separate rate cuts in 2019.\n",
            "\n",
            "Fast forward to the current scenario; we have an interest rate of 5.25% to 5.50% in July 2023, with subsequent adjustments influenced by economic markers. From the monetary policy report of the FOMC, it is suggested that sustained improvements in inflation data are required before rate cuts can be considered. The FOMC does not anticipate reducing the target range until greater confidence that inflation is moving sustainably toward 2% is achieved.\n",
            "\n",
            "At the Fed's June 2024 Meeting, the Federal Reserve left its benchmark interest rate unchanged and projected only one rate cut in 2024. This signals a cautious approach given persistent inflation above the targeted 2%.\n",
            "\n",
            "Although some experts suggest the Fed should cut rates sooner to support the economy in the face of rising unemployment risks, they also predict hefty rate cuts years down the line.\n",
            "\n",
            "Economic indicators do show the potential for a rate cut. Inflation has displayed improvements with the PCE index gradually declining. Job gains are strong and unemployment is low. Real GDP growth was modest while growth in private domestic demand remained robust.\n",
            "\n",
            "Despite these indications, the Fed appears resolute on achieving its inflation target before changing the target federal funds rate.\n",
            "\n",
            "To sum up, while there are hints of a potential rate cut, the Federal Reserve's commitment to achieving the target inflation rates and the relatively positive economic indicators suggest a cautious approach that may delay any rate cuts. \n",
            "\n",
            "Considering all of these pieces of information and the forecast from my research assistant, I believe there is a medium to low probability that the Federal Reserve will announce a rate cut by September 30, 2024.\n",
            "\n",
            "Probability: 35.0% - Confidence: 70.0%.\n",
            "\n",
            "\n",
            "Extracted probability percentage value (0-100): 35.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 3\n",
            "Input text is approx 1037 tokens.\n",
            "Output text is approx 371 tokens.\n",
            "Output Reasoning:\n",
            "The decision to cut rates will depend on a multitude of factors, including the state of the economy, inflation, unemployment, and the financial markets. Currently, the Federal Reserve seems to be exhibiting caution in its approach, emphasizing the need for sustained improvements in inflation data before considering rate cuts.\n",
            "\n",
            "From the data provided, several points stand out:\n",
            "\n",
            "1. The Federal Reserve left rates unchanged in its June meeting and projected only one rate cut in 2024, suggesting caution and a hawkish stance. \n",
            "\n",
            "2. The Fed's Monetary Policy Report suggests that major changes, such as a rate cut, will only be considered once there is greater confidence in achieving its inflation target of 2%. \n",
            "\n",
            "3. Though experts vary in their opinions, there is a general consensus that the Fed is likely to maintain a cautious approach with any rate cuts being spread over the next few years.\n",
            "\n",
            "4. Economic indicators are mixed but generally positive, with inflation showing modest improvement, job gains being strong, and GDP growth being modest. Unless there is a significant downturn or shock in the economy, the current positive indicators suggest a reduced need for rate cuts.\n",
            "\n",
            "5. The reduction of the Fed's holdings could eventually lead to lower interest rates, but this is a gradual process and not likely to immediately affect the target federal funds rate in the short term. \n",
            "\n",
            "Considering the information available, there seems little indication that the Reserve will cut the target federal funds rate before September 30, 2024, unless there is significant change in the economic climate. However, forecasting this is challenging due to the many factors at play, and while no rate cuts are currently signaled, unexpected events could alter this.\n",
            "\n",
            "Let's account for the uncertainties and potential unforeseen events, especially considering that there is over two months until the September meeting.\n",
            "\n",
            "Probability: 35.0% - Confidence: 80.0%\n",
            "\n",
            "Extracted probability percentage value (0-100): 35.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "+++++++++++ FINAL PROMPT (4) +++++++++++++++++\n",
            "Running final prompt...\n",
            "Input text is approx 1037 tokens.\n",
            "Output text is approx 394 tokens.\n",
            "\n",
            "Final prompt's individual (non-weighted) extracted probability percentage value (0-100): 25.0\n",
            "\n",
            "Rationale to submit:\n",
            "\n",
            "\n",
            "    *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
            "\n",
            "    * *Main LLM Model used: gpt-4*\n",
            "    * *Weighted formula: (0.2267)(27.5% [Forecaster A]) + (0.1867)(35.0% [Forecaster B]) + (0.2133)(35.0% [Forecaster C]) + (0.3733)(25.0% [Summary Forecaster])*\n",
            "    * *** FINAL WEIGHTED FORECAST: 29.6%***\n",
            "\n",
            "    ---\n",
            "\n",
            "    \n",
            "\n",
            "Successfully predicted 29.6% (0.29600000000000004) on question 26389\n",
            "Comment Success!\n",
            "Output Reasoning:\n",
            "To forecast whether the Federal Reserve will cut interest rates before September 30, 2024, I will consider several factors:\n",
            "\n",
            "1. **The Federal Reserve's Commitment to Sustain Positive Inflation**: The primary goal of the FOMC is to control inflation to a healthy level while minimizing unemployment. A rate cut is implemented to increase the money supply in the economy, stimulating borrowing and investment to boost economic activity and control inflation. However, according to the Monetary Policy Report, the FOMC emphasized the need to get more confident in sustainable 2% inflation before considering rate cuts. This suggests the Fed is currently hesitant to cut the rate until its inflation target is met.\n",
            "\n",
            "2. **The Fed's Announcement in June 2024 Meeting**: The announcement from the Fed's June 2024 meeting suggests that they may cut rates but only once within 2024, suggesting a cautious approach. However, it does not elaborate on when the cut may happen.\n",
            "\n",
            "3. **Economic Indicators**: The provided economic indicators show no pressing need to cut interest rates. Inflation seems under control, with the PCE gradually declining, and the economy is currently showing robust growth and low unemployment. These signs typically would suggest no immediate need for lowering rates.\n",
            "\n",
            "4. **Expert Opinions**: Some anticipate possible cuts over the next two to three years, while others argue the rates should be cut sooner. These opinions indicate uncertainty as there is no consensus in expert views.\n",
            "\n",
            "Taking into account the factors above and noting biases in forecasting direction changes from the status quo, my forecast will lean toward the Federal Reserve maintaining their cautious approach and not making a rate cut before September 30, 2024. \n",
            "\n",
            "The scenario that could lead to a rate cut would likely involve a significant increase in inflation or a massive unemployment surge. Given the reports, neither of these seems likely to occur before the forecasted deadline.\n",
            "\n",
            "Probability: 25.0% - Confidence: 70.0%\n",
            "\n",
            "FINAL WEIGHTED FORECAST:\n",
            "29.6%\n",
            "\n",
            "Overall cost was: $0.045250000000000005\n",
            "\n",
            "################ NEXT QUESTION #################\n",
            "\n",
            "Now Forecasting Question:\n",
            "26389 Will the Federal Reserve cut interest rates before September 30, 2024?\n",
            "\n",
            "Run 3\n",
            "\n",
            "Using OpenAI endpoint for model: gpt-4-turbo\n",
            "Getting Perplexity recent data...\n",
            "\n",
            "Input text is approx 367 tokens.\n",
            "Output text is approx 15 tokens.\n",
            "The completed question posed to perplexity reads: What is the most recent news available and prior occurrences related to the possibility of, and any indicators or evidence of the Federal Reserve cutting interest rates before September 30, 2024?  Today's date is 2024-07-23.\n",
            "Generated research from perplexity:\n",
            "The most recent news available suggests that the Federal Reserve is likely to cut interest rates before September 30, 2024. Here are some key points and indicators:\n",
            "\n",
            "1. **Federal Reserve Officials' Statements**: Top Federal Reserve officials have indicated that they are \"closer\" to cutting interest rates due to improved inflation data. This suggests that the Fed is considering rate cuts in the near future.\n",
            "\n",
            "2. **Traders' Consensus**: Traders are now 100% certain that the Federal Reserve will cut interest rates by September. The likelihood of a quarter percentage point reduction in the Fed's target range for federal funds stands at 93.3%, with a 6.7% probability of a half percentage point decrease during the same period.\n",
            "\n",
            "3. **Inflation Data**: The consumer price index report for June showed a 0.1% decline compared to the previous month, leading to a drop in the annual inflation rate to 3%, a three-year low. This improvement in inflation data has increased the likelihood of a rate cut.\n",
            "\n",
            "4. **Federal Reserve Chair Jerome Powell's Comments**: Powell has emphasized that the Fed would not delay rate cuts until inflation reaches the 2% target rate due to the delayed impacts of tightening measures. He stressed the importance of gaining 'greater confidence' in inflation returning to the 2% threshold, which suggests that the Fed is open to rate cuts if inflation continues to trend downward.\n",
            "\n",
            "5. **Market Expectations**: Mortgage rates have fallen slightly in recent months, and some experts believe mortgage rates could fall 0.25 to 0.75% when and if the Fed cuts rates for the first time in 2024. This indicates that the market is anticipating a rate cut.\n",
            "\n",
            "6. **Upcoming Fed Meetings**: The Federal Reserve is scheduled to make decisions on interest rates on July 31 and September 18, with no meetings scheduled for August. This means that the next opportunity for a rate cut is at the end of July.\n",
            "\n",
            "7. **Prior Projections**: In June, the Federal Reserve was expected to maintain interest rates steady, with updated economic forecasts indicating a reduced likelihood of rate cuts this year and a postponed initiation of monetary easing measures. However, recent data has shifted the expectations towards a rate cut.\n",
            "\n",
            "Overall, the recent news and data suggest that the Federal Reserve is likely to cut interest rates before September 30, 2024, with a high probability of a rate cut by September.\n",
            "\n",
            "Total perplexity call cost: $0.0057072\n",
            "\n",
            "Running initial prompt 1\n",
            "Input text is approx 1184 tokens.\n",
            "Output text is approx 624 tokens.\n",
            "Output Reasoning:\n",
            "To forecast whether the Federal Reserve will cut interest rates before September 30, 2024, I will systematically analyze the provided information, focusing on both recent trends and the implications from data points.\n",
            "\n",
            "**1. Federal Reserve's Historical Actions and Patterns:**\n",
            "Historical precedents form a baseline understanding. Prior to 2020 and 2019, rate cuts were reactionary to particular economic conditions, primarily as tools to combat recessionary pressures or below-target inflation levels. Past performance indicates flexibility in policy to respond to shifting economic data.\n",
            "\n",
            "**2. Current Economic Data and Trends:**\n",
            "The significant and recent data showing a decline in the annual inflation rate to 3%, a three-year low, indicates a cooling of inflationary pressures. Historically, the Federal Reserve's primary mandate involves managing inflation while fostering employment growth, and decreasing inflation rates are typically met with monetary loosening measures, including rate cuts. \n",
            "\n",
            "**3. Federal Reserve Officials’ Recent Statements:**\n",
            "Recent statements from Federal Reserve officials, noting that they are \"closer” to rate cuts, illustrate a policy stance that is adaptable to the evolving economic landscape. Jerome Powell’s commentary on not waiting for the 2% inflation target further suggests readiness to act preemptively against perceived economic threats.\n",
            "\n",
            "**4. Market Expectations and External Opinions:**\n",
            "Traders and market consensus are currently overwhelmingly leaning towards an impending rate cut by September, as indicated by a 100% certainty among traders about this action. The financial markets often price-in such expected outcomes based on available public and private information, reflecting broad expectations.\n",
            "\n",
            "**5. Upcoming Federal Reserve Meetings:**\n",
            "Given the dates of forthcoming FOMC meetings – July 31 and September 18 – opportunities for policy adjustments are evident. The non-holding of meetings in August focuses the decision-making to these specific dates, which are the final meetings before the September 30 deadline.\n",
            "\n",
            "**6. Comparison with Previous Forecasts and Adjustments:**\n",
            "Earlier in June, expectations were set against rate cuts; however, the drastic shift in forecasts following updated economic data indicates highly responsive and data-dependent decision-making processes by the Fed.\n",
            "\n",
            "**Assessment of Possible Countering Factors:**\n",
            "While the trend leans towards a rate cut, it's essential to consider the possibility of unexpected economic shocks or higher-than-anticipated future inflationary readings that might sway the Fed's decision. However, given current trajectories and statements, these appear less likely.\n",
            "\n",
            "---\n",
            "\n",
            "**Final Probability Forecast:**\n",
            "Based on the trends of current economic indicators suggesting a cooling of inflation, combined with strong opining and market expectations for a rate cut, and the upcoming meetings scheduled before the cut-off date, it seems highly probable that the FOMC will announce a rate cut.\n",
            "\n",
            "**Probability: 93.0% - Confidence: 85.0%**\n",
            "\n",
            "This reflects high certainty based on available data and the pronounced directional indications from influential market actors and federal officials. However, the confidence level accounts for potential unforeseen economic variances or global events impacting the U.S. economic outlook within a short frame, which could affect the decision-making process of the Federal Reserve.\n",
            "\n",
            "Extracted probability percentage value (0-100): 93.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 2\n",
            "Input text is approx 1089 tokens.\n",
            "Output text is approx 618 tokens.\n",
            "Output Reasoning:\n",
            "To determine the likelihood of the Federal Reserve cutting interest rates before September 30, 2024, I will analyze the information and consider an outside view based on previous rate cut tendencies, and blend this with context-specific insights like economic indicators and recent statements from Federal Reserve officials.\n",
            "\n",
            "**Step-by-Step Reasoning**:\n",
            "\n",
            "1. **Historical Context**: According to the historical information provided, the last several occasions when the Fed cut rates were in response to specific economic conditions, notably in March 2020 due to the pandemic-induced economic crisis, and three times in 2019 during a period of economic slowing and uncertainty. These decisions often follow patterns of economic downturns, sharp declines in employment rates, or significantly low inflation rates.\n",
            "\n",
            "2. **Current Inflation Data**: The inflation rate is reportedly at a three-year low of 3%, indicating an easing of inflationary pressure. Historically, the Fed's rate cuts often aim to avoid deflation and encourage spending when inflation falls precipitously or fails to approach the Fed’s target rate steadily.\n",
            "\n",
            "3. **Federal Reserve Officials’ Latest Statements**: Recent statements suggest a significant inclination towards rate cuts, considering that inflation is cooling down and is closer to the Fed’s long-term target of 2%. That officials mention they are closer to cutting rates adds weight to the likelihood of imminent cuts.\n",
            "\n",
            "4. **Market Sentiments and Traders’ Expectations**: The fact that traders believe there is a high probability of a forthcoming cut before September indicates market consensus, which can be a self-fulfilling forecast. Financial markets tend to anticipate the Fed’s moves based on available economic data and can influence decision-making indirectly.\n",
            "\n",
            "5. **Timing and Urgency**: The urgency stressed in Jerome Powell’s remarks and the specific timing provided (the next possible dates for a decision are July 31 and September 18) suggests that a decision could very well come soon. There is only a little over two months remaining until the cut-off date, and the specified meetings align perfectly with this timeframe.\n",
            "\n",
            "6. **Recent Momentum in Forecasts**: The contrast between earlier projections (June) of steady rates vs. the current heightened expectation for a cut indicates a significant shift based on recent data—this shift being significant enough to reconsider earlier rate projections is relevant.\n",
            "\n",
            "**Final Analysis and Probability Assignment**:\n",
            "Given the combination of low inflation reaching near the Fed's comfort zone, guidance from Federal Reserve officials, market expectations historically preceding actual moves by the Fed, and the immediacy suggested by upcoming Fed meetings, there is a strong case for anticipating a rate cut before September 30, 2024.\n",
            "\n",
            "Based on the analysis considering both the base rate of occurrence from reference classes in similar economic conditions and applying new information that tilts toward a rate cut decision, the following probability is provided:\n",
            "\n",
            "**Probability: 87.5% - Confidence: 95.0%**\n",
            "\n",
            "This assessment holds a high degree of confidence due to recent, consistent indicators from various reliable sources (Federal Reserve, market data) suggesting alignment toward a potential rate cut on or before the specified date.\n",
            "\n",
            "Extracted probability percentage value (0-100): 87.5\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 3\n",
            "Input text is approx 1132 tokens.\n",
            "Output text is approx 544 tokens.\n",
            "Output Reasoning:\n",
            "To determine the probability of the Federal Reserve cutting interest rates before September 30, 2024, step-by-step analysis is required based on current indicators, professional intuition, and historical context:\n",
            "\n",
            "1. **Federal Reserve's Recent Policy and Statements**: Current statements from Federal Reserve officials indicate a leaning towards cutting rates, primarily driven by positive changes in inflation data. Such trends often play a critical role in shifting policy directions.\n",
            "\n",
            "2. **Economic Indicators and Market Sentiments**: Trading data showing a 100% certainty among traders for a rate cut, and a 93.3% likelihood specifically of a quarter-point reduction, reflects strong market anticipation of this move. Markets typically digest multiple data sources and expert analyses to form these probabilities, which should be given significant weight in forecasting.\n",
            "\n",
            "3. **Inflation Trends**: The downward trend in inflation is significant, considering that monetary policy adjustments such as rate cuts are often responses to sustained shifts in economic indicators like inflation. Current data show that inflation is closer to the Fed's comfort zone.\n",
            "\n",
            "4. **Statements from Fed Chair Jerome Powell**: Powell's recent remarks underscore a readiness to cut rates even if inflation hasn't fully hit the target, provided the trend is favorable. This flexibility in policy-making further supports the likelihood of an impending rate cut.\n",
            "\n",
            "5. **Timing of Fed Meetings**: The upcoming Federal Reserve meeting on July 31 and another on September 18 provide two distinct windows where a rate cut announcement could be made. The proximity of these dates to the current date (July 23, 2027) adds immediacy to the decision-making process.\n",
            "\n",
            "6. **Historical Precedents**: The Fed's response in recent years, including the cuts in March 2020 and throughout 2019, demonstrate a willingness to adapt monetary policy to changing economic conditions. Though past performance is not a definitive predictor, it helps outline the Fed's behavioral pattern.\n",
            "\n",
            "7. **Fine Print and Resolution Source**: The resolution of this question depends solely on an announcement being made before the deadline, regardless of when the cut is actually implemented. This detail is crucial as it allows for the possibility of a late announcement with a future effective date, extending the time frame in which this resolution condition can be met.\n",
            "\n",
            "Bringing together these points, the indicators strongly suggest that the Federal Reserve is gearing up for a rate cut, supported by favorable economic conditions, market expectations, and official statements hinting at such a move. Given that rookie forecasters tend to be underconfident and that major changes like a rate cut often have strong preceding signals (which we observe here), I will moderately extremize towards certainty.\n",
            "\n",
            "**Probability: 95.0% - Confidence: 90.0%**\n",
            "\n",
            "Extracted probability percentage value (0-100): 95.0\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "+++++++++++ FINAL PROMPT (4) +++++++++++++++++\n",
            "Running final prompt...\n",
            "Input text is approx 1132 tokens.\n",
            "Output text is approx 499 tokens.\n",
            "\n",
            "Final prompt's individual (non-weighted) extracted probability percentage value (0-100): 93.4\n",
            "\n",
            "Rationale to submit:\n",
            "\n",
            "\n",
            "    *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
            "\n",
            "    * *Main LLM Model used: gpt-4-turbo*\n",
            "    * *Weighted formula: (0.1906)(93.0% [Forecaster A]) + (0.213)(87.5% [Forecaster B]) + (0.2018)(95.0% [Forecaster C]) + (0.3946)(93.4% [Summary Forecaster])*\n",
            "    * *** FINAL WEIGHTED FORECAST: 92.4%***\n",
            "\n",
            "    ---\n",
            "\n",
            "    \n",
            "\n",
            "Successfully predicted 92.4% (0.924) on question 26389\n",
            "Comment Success!\n",
            "Output Reasoning:\n",
            "To produce an accurate forecast for whether the Federal Reserve will cut interest rates before September 30, 2024, I need to carefully consider the current economic indicators, the statements from Federal Reserve officials, market expectations, and any recent changes in economic forecasts and data. Here is my detailed reasoning:\n",
            "\n",
            "1. **Current Economic Data and Inflation Trends**: The most recent reports show a decline in inflation, with the consumer price index dropping by 0.1% month-over-month and the annual rate reaching a three-year low of 3%. Lower inflation is a critical factor that the Fed takes into account when deciding to cut rates.\n",
            "\n",
            "2. **Federal Reserve Official Statements and Market Expectations**: Recent statements by Federal Reserve officials hint at a proximity to rate cuts, reflecting a readiness to alter policy in response to improved inflation data. Furthermore, market traders exhibit strong expectations (100% certainty) of a rate cut by September, which influences the sentiment around monetary policy.\n",
            "\n",
            "3. **Scheduled Federal Reserve Meetings**: The key opportunities for announcing a rate cut are during the forthcoming FOMC meetings on July 31 and September 18. No rate decision meetings are scheduled in August, so these are pivotal dates.\n",
            "\n",
            "4. **Historical Context and Policy Adjustments**: The Fed's history indicates responsiveness to changing economic conditions. Given past behavior during downturns or periods of lower inflation, the likelihood of an interest rate cut following a sustained decrease in inflation seems plausible.\n",
            "\n",
            "5. **Impact of Forward Guidance**: Statements by Federal Reserve Chair Jerome Powell indicate a proactive stance in adjusting rates ahead of achieving the 2% inflation target, which implies a potential earlier rate cut if inflation trends downward consistently.\n",
            "\n",
            "6. **Market Reaction and Mortgage Rates**: There's a notable anticipation in the market for a prospective rate cut, exemplified by the slight fall in mortgage rates. Market behavior often reflects expectations that can also pressure policy directions.\n",
            "\n",
            "Given this analysis, several factors strongly suggest that a rate cut is likely before September 30, 2024. The downward trend in inflation, affirmative signals from Fed officials, strong market expectations, and the immediate timeline of upcoming FOMC meetings all converge to support the likelihood of a rate cut.\n",
            "\n",
            "Considering all these factors and the weight of economic signals and official guidance, while also extremizing slightly towards certainty due to the common underconfidence in forecasting, I would forecast the following probability with high confidence based on the analysis:\n",
            "\n",
            "Probability: 93.4% - Confidence: 88.0%\n",
            "\n",
            "FINAL WEIGHTED FORECAST:\n",
            "92.4%\n",
            "\n",
            "Overall cost was: $0.05696\n",
            "\n",
            "################ NEXT QUESTION #################\n",
            "\n",
            "AVERAGED FINAL FORECAST: 62.8%\n",
            "FINAL COMMENT:\n",
            "Averaging 3 independently generated forecasts (66.5%, 29.6%, 92.4%) generated on different main LLM models (gpt-4o, gpt-4, gpt-4-turbo) to get a final forecast value of **62.8%**.\n",
            "\n",
            "Successfully predicted 62.8% (0.628) on question 26389\n",
            "Comment Success!\n",
            "################ NEXT QUESTION #################\n",
            "\n",
            "Finished forecasting on 1 questions.\n"
          ]
        }
      ],
      "source": [
        "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "#if USE_METACULUS_PROXY_ENDPOINT:\n",
        "#  client = OpenAI(base_url='https://www.metaculus.com/proxy/openai/v1/chat/completions')\n",
        "#else:\n",
        "#  client = OpenAI()\n",
        "openai_client = OpenAI()\n",
        "\n",
        "model = OPEN_AI_MODEL\n",
        "\n",
        "prompt_templates = [prompt_template_v1 + QUESTION_INFO_TEMPLATE, prompt_template_v2 + QUESTION_INFO_TEMPLATE, prompt_template_v3 + QUESTION_INFO_TEMPLATE]\n",
        "\n",
        "forecasted_count = 0\n",
        "\n",
        "for question_to_forecast_dict in yield_all_questions():\n",
        "  if forecasted_count >= MAX_QUESTIONS_TO_FORECAST:\n",
        "    break\n",
        "  if QUESTION_IDS_TO_FORECAST is not None and question_to_forecast_dict[\"id\"] not in QUESTION_IDS_TO_FORECAST:\n",
        "    continue\n",
        "\n",
        "  final_forecasts = []\n",
        "\n",
        "  for q in range(0, NUM_FORECASTS_TO_AVERAGE):\n",
        "\n",
        "    print(\"Now Forecasting Question:\")\n",
        "    print(question_to_forecast_dict[\"id\"], question_to_forecast_dict[\"title\"])\n",
        "    print(\"\")\n",
        "    print(\"Run %s\" % (q+1))\n",
        "    print(\"\")\n",
        "\n",
        "    if NUM_FORECASTS_TO_AVERAGE>1:\n",
        "      model = MODELS_TO_RUN[q % len(MODELS_TO_RUN)]\n",
        "      if model in METACULUS_SUPPORTED_MODELS:\n",
        "        print(\"Using Metaculus endpoint for model: %s\" % model)\n",
        "        USE_METACULUS_PROXY_ENDPOINT = True\n",
        "      else:\n",
        "        print(\"Using OpenAI endpoint for model: %s\" % model)\n",
        "        USE_METACULUS_PROXY_ENDPOINT = False\n",
        "\n",
        "    #define perplexity research to use\n",
        "    perplexity_total_cost = \"N/A\"\n",
        "\n",
        "    summary_report = \"\" # ?\n",
        "\n",
        "    # set summary_report to the perplexity recent search if enabled\n",
        "    if USE_PERPLEXITY_RECENT:\n",
        "      print(\"Getting Perplexity recent data...\")\n",
        "      print (\"\")\n",
        "\n",
        "      #get prompt completion for use with perplexity\n",
        "      if USE_METACULUS_PROXY_ENDPOINT:\n",
        "        probability, confidence, perplexity_recent_prompt_completion, completion_input_cost, completion_output_cost, completion_total_cost = run_llm_metaculus(today, question_to_forecast_dict, prompt_template_get_perplexity_question, summary_report, model, looking_for_probability=False)\n",
        "      else:\n",
        "        probability, confidence, perplexity_recent_prompt_completion, completion_input_cost, completion_output_cost, completion_total_cost = run_llm(today, openai_client, question_to_forecast_dict, prompt_template_get_perplexity_question, summary_report, model, looking_for_probability=False)\n",
        "\n",
        "      perplexity_recent_prompt = perplexity_recent_prompt_completion if (\"What is the most recent news available and prior occurrences related to\".lower() in perplexity_recent_prompt_completion.lower()) else (\"What is the most recent news available and prior occurrences related to the possibility of, and any indicators or evidence of \" + perplexity_recent_prompt_completion)\n",
        "\n",
        "      perplexity_recent_prompt = perplexity_recent_prompt + \"  Today's date is \" + today + \".\"\n",
        "\n",
        "      print(f\"The completed question posed to perplexity reads: {perplexity_recent_prompt}\")\n",
        "      perplexity_content, perplexity_cost = call_perplexity(perplexity_recent_prompt, perplexity_api_key)\n",
        "\n",
        "      summary_report = perplexity_content\n",
        "      perplexity_total_cost = completion_total_cost + perplexity_cost\n",
        "\n",
        "    # need to iterate through prompts here\n",
        "    all_forecasts = []\n",
        "    overall_cost = 0\n",
        "\n",
        "    i = 0\n",
        "    for prompt_template in prompt_templates:\n",
        "      i+=1\n",
        "      print(\"Running initial prompt %s\" % i)\n",
        "      if USE_METACULUS_PROXY_ENDPOINT:\n",
        "        try: # i'm letting it possibly run twice, in case it fails the first time due to returning the numerical result in a weird way\n",
        "          probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm_metaculus(today, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "        except:\n",
        "          probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm_metaculus(today, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "      else:\n",
        "        try:\n",
        "          probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm(today, openai_client, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "        except:\n",
        "          probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm(today, openai_client, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "      all_forecasts.append((probability, confidence, gpt_text, input_cost, output_cost, total_cost))\n",
        "      overall_cost += total_cost\n",
        "      print(f\"Output Reasoning:\")\n",
        "      print(gpt_text)\n",
        "      print(\"\")\n",
        "      print(\"Extracted probability percentage value (0-100): %s\" % probability)\n",
        "      print(\"\")\n",
        "      print(\"~~~~ NEXT PROMPT ~~~~\")\n",
        "      print(\"\")\n",
        "\n",
        "    final_prompt_part2_dict = {\n",
        "        \"forecaster1\": all_forecasts[0][2],\n",
        "        \"forecaster2\": all_forecasts[1][2],\n",
        "        \"forecaster3\": all_forecasts[2][2],\n",
        "    }\n",
        "\n",
        "    formatted_final_prompt_part2 = replace_keys(final_prompt_part2, final_prompt_part2_dict)\n",
        "\n",
        "    print(\"+++++++++++ FINAL PROMPT (4) +++++++++++++++++\")\n",
        "\n",
        "    final_prompt_template = final_prompt_part1 + QUESTION_INFO_TEMPLATE + formatted_final_prompt_part2\n",
        "\n",
        "    print(\"Running final prompt...\")\n",
        "\n",
        "    if USE_METACULUS_PROXY_ENDPOINT:\n",
        "      try: # i'm letting it possibly run twice, in case it fails the first time due to returning the numerical result in a weird way\n",
        "        probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm_metaculus(today, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "      except:\n",
        "        probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm_metaculus(today, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "    else:\n",
        "      try:\n",
        "        probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm(today, openai_client, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "      except:\n",
        "        probability, confidence, gpt_text, input_cost, output_cost, total_cost = run_llm(today, openai_client, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "    print(\"\")\n",
        "\n",
        "    print(\"Final prompt's individual (non-weighted) extracted probability percentage value (0-100): %s\" % probability)\n",
        "    print(\"\")\n",
        "\n",
        "    if USE_CONFIDENCE:\n",
        "      total_confidence = 0\n",
        "      for forecast in all_forecasts:\n",
        "        total_confidence += forecast[1]\n",
        "      total_confidence += 2.0*confidence\n",
        "      forecaster1_weight = round(all_forecasts[0][1]/total_confidence,4)\n",
        "      forecaster2_weight = round(all_forecasts[1][1]/total_confidence,4)\n",
        "      forecaster3_weight = round(all_forecasts[2][1]/total_confidence,4)\n",
        "      forecaster4_weight = round(2.0*confidence/total_confidence,4)\n",
        "\n",
        "    else:\n",
        "      forecaster1_weight = 0.2\n",
        "      forecaster2_weight = 0.2\n",
        "      forecaster3_weight = 0.2\n",
        "      forecaster4_weight = 0.4\n",
        "\n",
        "    weighted_forecast = forecaster1_weight*float(all_forecasts[0][0]) + forecaster2_weight*float(all_forecasts[1][0]) + forecaster3_weight*float(all_forecasts[2][0]) + forecaster4_weight*float(probability)\n",
        "    weighted_forecast = round(weighted_forecast,1)\n",
        "    overall_cost = overall_cost + total_cost\n",
        "\n",
        "    #create summary strings for comments:\n",
        "    header_string = f\"\"\"\n",
        "    *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
        "\n",
        "    * *Main LLM Model used: {model}*\n",
        "    * *Weighted formula: ({forecaster1_weight})({all_forecasts[0][0]}% [Forecaster A]) + ({forecaster2_weight})({all_forecasts[1][0]}% [Forecaster B]) + ({forecaster3_weight})({all_forecasts[2][0]}% [Forecaster C]) + ({forecaster4_weight})({probability}% [Summary Forecaster])*\n",
        "    * *** FINAL WEIGHTED FORECAST: {weighted_forecast}%***\n",
        "\n",
        "    ---\n",
        "\n",
        "    \"\"\"\n",
        "    print('Rationale to submit:')\n",
        "    print(\"\")\n",
        "    print(header_string)\n",
        "    print(\"\")\n",
        "\n",
        "    if SUBMIT_FORECASTS and weighted_forecast is not None:\n",
        "      predict(question_to_forecast_dict[\"id\"], float(weighted_forecast))\n",
        "      comment(question_to_forecast_dict[\"id\"], header_string + \"PERPLEXITY INFO\\n\\n\" + summary_report + \"\\n\\n---\\n\\n\" + \"SUMMARY FORECASTER RATIONALE\\n\\n\" + gpt_text)\n",
        "    final_forecasts.append(float(weighted_forecast))\n",
        "\n",
        "    print(f\"Output Reasoning:\")\n",
        "    print(gpt_text)\n",
        "    print(\"\")\n",
        "    print(\"FINAL WEIGHTED FORECAST:\")\n",
        "    print(f\"{weighted_forecast}%\")\n",
        "    print(\"\")\n",
        "    print(f\"Overall cost was: ${overall_cost}\")\n",
        "    print(\"\")\n",
        "    print(\"################ NEXT QUESTION #################\")\n",
        "    print(\"\")\n",
        "\n",
        "  if NUM_FORECASTS_TO_AVERAGE>1:\n",
        "    #average the forecasts and make a final one\n",
        "    assert len(final_forecasts) == NUM_FORECASTS_TO_AVERAGE\n",
        "    final_forecast = round(sum(final_forecasts)/len(final_forecasts),1)\n",
        "    final_comment = \"Averaging %s independently generated forecasts (%s) generated on different main LLM models (%s) to get a final forecast value of **%s%%**.\" % (NUM_FORECASTS_TO_AVERAGE, \", \".join([(\"%s%%\" % f) for f in final_forecasts]), \", \".join(MODELS_TO_RUN), final_forecast)\n",
        "    print(\"AVERAGED FINAL FORECAST: %s%%\" % final_forecast)\n",
        "    print(\"FINAL COMMENT:\")\n",
        "    print(final_comment)\n",
        "    print(\"\")\n",
        "    if SUBMIT_FORECASTS:\n",
        "      predict(question_to_forecast_dict[\"id\"], float(final_forecast))\n",
        "      comment(question_to_forecast_dict[\"id\"], final_comment)\n",
        "    print(\"################ NEXT QUESTION #################\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "  forecasted_count += 1\n",
        "\n",
        "print(\"Finished forecasting on %s questions.\" % forecasted_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qfSjn0L_8I3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}