{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joe-segal/metaculus-bot-forecaster/blob/main/JMS_Metaculus_Bot_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Forecasting Bot\n",
        "*Created by Kirill and Tom, revised by Ryan*\n",
        "\n",
        "The code below is used for making LLM-powered forecasts in Metaculus' [AI benchmarking competition](https://www.metaculus.com/project/ai-benchmarking-pilot/).\n",
        "\n",
        "Specifically, it does the following:\n",
        "\n",
        "* Gets questions from the project page using the Metaculus API\n",
        "* Gets four separate forecasts from the LLM, three independently and the fourth assessing the reasoning of the first three and producing its own.\n",
        "* Predicts on the Metaculus questions and shares a comment describing the reasoning of the fourth LLM forecast.\n",
        "\n",
        "Features and options:\n",
        "\n",
        "* Allows you to choose whether it repredicts on questions it's already forecasted on or ignores them.\n",
        "* Allows for the use of [Perplexity search](https://www.perplexity.ai/) for additional research, using a prompt formed by an LLM.\n",
        "    * *Previously this allowed for the use of pre-computed Perpelxity results, but this is no longer supported by Metaculus.*\n",
        "* Can be used with an automated workflow via Github actions to monitor the project for new open questions and make forecasts when there are some\n",
        "    * See [this Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for how to set this up"
      ],
      "metadata": {
        "id": "zMlSOSdSYCds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸš¨ðŸš¨ðŸš¨ Warning ðŸš¨ðŸš¨ðŸš¨\n",
        "\n",
        "**You are responsible for monitoring the costs of your implementation, especially if using the automated Github workflow. Cost estimates computed by this notebook are rough estimates only, make sure to check and monitor how much you are spending and the funds in your relevant accounts.**"
      ],
      "metadata": {
        "id": "TZ5X6zf7bYT-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqR47EYbh6p"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "### Make a Metaculus Bot Account\n",
        "The first step will be to make a Metaculus bot account. Instructions for how to do this have likely already been provided to you, either via a page on Metaculus or at an event.\n",
        "\n",
        "### Secrets and Tokens\n",
        "\n",
        "You need to set secrets 1) and 2) in order to make forecasts. Secrets 3) and 4) are necessary if you will be using Perplexity research.\n",
        "\n",
        "1) METACULUS_TOKEN (you can find it or create it here - https://www.metaculus.com/admin/authtoken/tokenproxy/, or ask Metaculus to share it with you).\n",
        "\n",
        "2) OPENAPI_API_KEY - (you can find it here https://platform.openai.com/settings/profile?tab=api-keys).\n",
        "\n",
        "3) PERPLEXITY_API_KEY - You can generate an API key here: https://docs.perplexity.ai/docs/getting-started\n",
        "\n",
        "These secrets can be set in your Google colab account using the key on the left side.\n",
        "\n",
        "*See the [Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for special instructions necessary for setting your secrets in Github if you intend to use the automated Github action.*\n",
        "\n",
        "*Note: previously this also used a QUESTIONS_API_KEY which got some precomputed Perplexity results stored by Metaculus, but this is no longer supported by Metaculus.*\n",
        "\n",
        "### Setting Inputs\n",
        "\n",
        "Once your tokens are set correctly, you can proceed to the [Inputs section](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=6cbruBaVtaZh). That should be the only section most users will need. More advanced users can edit the [Setup](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=tNl_mbJaX60R) and [Code](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=k8vtze4SXtR3) sections if desired, but this is not recommended unless you have coding experience."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "It is recommended that you do not edit these cells unless you have coding experience.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tNl_mbJaX60R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css(*args, **kwargs):\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "#according to this link the above wraps the output text: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results"
      ],
      "metadata": {
        "id": "girVrSlJkWUL",
        "outputId": "10095fe4-268c-4848-ec69-705db22455c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HifodCwcGU0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "09fbfd78-e951-4915-8e39-053871585745"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import tiktoken\n",
        "import re\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "#use the below to detect if it's being run in google colab, if it's not this skips an error\n",
        "def in_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoELZnYOGXsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d299786d-89af-48d7-8e27-80aeb32989b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading secrets from userdata (Google Colab)\n"
          ]
        }
      ],
      "source": [
        "#the below is used to get secrets when using github actions to automate\n",
        "#initialize\n",
        "token = None\n",
        "#questions_api_key = None\n",
        "perplexity_api_key = None\n",
        "\n",
        "# Function to load secrets from the specified path\n",
        "def load_secrets(secrets_path):\n",
        "    try:\n",
        "        with open(secrets_path, 'r') as secrets_file:\n",
        "            secrets = json.loads(secrets_file.read())\n",
        "            for k, v in secrets.items():\n",
        "                os.environ[k] = v\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading secrets from {secrets_path}: {e}\")\n",
        "\n",
        "# Main code block\n",
        "try:\n",
        "    if 'secretsPath' in globals():\n",
        "        print(f\"secretsPath exists: {secretsPath}\")\n",
        "        load_secrets(secretsPath)\n",
        "\n",
        "        token = os.environ['METACULUS_TOKEN']\n",
        "        #questions_api_key = os.environ['QUESTIONS_API_KEY']\n",
        "        perplexity_api_key = os.environ['PERPLEXITY_API_KEY']\n",
        "    else:\n",
        "        raise NameError(\"secretsPath not defined\")\n",
        "except NameError:\n",
        "    print(\"Loading secrets from userdata (Google Colab)\")\n",
        "    token = userdata.get('METACULUS_TOKEN')\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    #questions_api_key = userdata.get('QUESTIONS_API_KEY')\n",
        "    perplexity_api_key = userdata.get('PERPLEXITY_API_KEY')\n",
        "except KeyError as e:\n",
        "    print(f\"Missing required environment variable: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs\n",
        "\n",
        "The cell below contains all of the main settings that you can change. See comments in the cell for an explanation of each. Modify them as you see fit and then run all of the cells below to forecast.\n",
        "\n",
        "*You can press Ctrl+F10 to run all of the cells after the selected one.*"
      ],
      "metadata": {
        "id": "6cbruBaVtaZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 3349  # 3129 is ID of AI Becnhmarking Pilot project. We kindly ask you not to forecast on any public tournaments or public questions in general\n",
        "MAX_QUESTIONS_TO_FORECAST = 25  # You can set it to some small number for testing or to 1_000_000 to forecast on all available questions\n",
        "REPREDICT = False # if this is false it won't predict on questions it has previously already predicted on. Set it to true to repredict on all open questions, even if it has made previous predictions.\n",
        "SUBMIT_FORECASTS = True # If set to False - forecast, but don't submit results to Metaculus platform. If set to True - forecast, and submit results to Metaculus platform\n",
        "USE_PERPLEXITY_RECENT = True # If set to true the perplexity search used is one that looks for the most recent news on the subject using a GPT prompt completion informed by the forecasting question.\n",
        "QUESTION_IDS_TO_FORECAST = None # Set to None to disable custom filtering by ID. Set to a list of IDs to only forecast on selected questions, i.e. [24191, 24190, 24189]\n",
        "#QUESTION_IDS_TO_FORECAST = [26236]\n",
        "\n",
        "# Use this to run your own question, not pulled from Metaculus\n",
        "ANSWER_MANUAL_QUESTION = False\n",
        "manual_question = \"Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\"\n",
        "manual_question_dict = {\n",
        "  'id': None,\n",
        "  'title': manual_question,\n",
        "  'description': manual_question,\n",
        "  'resolution_criteria': manual_question,\n",
        "  'fine_print': manual_question\n",
        "  }\n",
        "if ANSWER_MANUAL_QUESTION:\n",
        "  SUBMIT_FORECASTS = False\n",
        "\n",
        "OPEN_AI_MODEL = 'gpt-4'\n",
        "PERPLEXITY_MODEL = 'llama-3-sonar-large-32k-online'\n",
        "\n",
        "# The forecaster weights are used to produce a weighted average of the forecasts. You can adjust these weights to favor a certain forecaster/prompt more heavily.\n",
        "# Weights should sum to 1.\n",
        "forecaster1_weight = 0.2\n",
        "forecaster2_weight = 0.2\n",
        "forecaster3_weight = 0.2\n",
        "forecaster4_weight = 0.4\n",
        "\n",
        "# Prompts\n",
        "# The prompts used are below, these can be edited to hone your LLM forecasts.\n",
        "# Here is a glossary of the variables that can be inserted and used in the prompts.\n",
        "# [[title]]: This is the question text, what shows up at the top of the Metaculus question page\n",
        "# [[resolution_criteria]]: This is the resolution criteria section of the question, excluding fine print\n",
        "# [[fine_print]]: This is the fine print section of the question.\n",
        "# [[background]]: This is the background section of the resolution criteria.\n",
        "# [[today]]: The current date\n",
        "# [[forecaster1]] through {forecaster3}: These are the LLM outputs of forecasters 1 through 3, currently being used to feed into the input of forecaster 4 for it to assess in its own forecast.\n",
        "# [[summary_report]]: This is research from Perplexity. If USE_PERPLEXITY_RECENT is True, this will be the Perplexity info returned when the output of LLM_question_completion is passed to Perplexity.\n",
        "                  # If USE_PERPLEXITY_RECENT is False and ENABLE_PERPLEXITY_RESEARCH is True, it will return pre-computed Perplexity research on the question stored by Metaculus.\n",
        "                  # If both are false it will not return anything.\n",
        "\n",
        "# The LLM_question_completion prompt is used to ask the LLM what question it should ask Perplexity, if using USE_PERPLEXITY_RECENT\n",
        "LLM_question_completion = \"\"\"\n",
        "You're being asked the following forecasting question:\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "And it has these specific resolution details:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Fine print:\n",
        "[[fine_print]]\n",
        "\n",
        "To get the latest news that will help you forecast on the question, you need to ask your web search tool one question that would be most valuable to help you forecast\n",
        "on this question. The question should be posed so that the web search tool will provide you with the most recent information, including the latest information on the progress toward\n",
        "the criteria in the forecasting question being met. Please complete the sentence below with the most valuable question to ask:\n",
        "\n",
        "\"What is the most recent news available and prior occurrences related to. . . \"\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 1 is used by forecaster 1, with PROMPT_TEMPLATE appended to the end\n",
        "prompt1 = \"\"\"\n",
        "You are a professional forecaster interviewing for a job. The interviewer is also a professional forecaster, with a strong track record of accurate forecasts of the future.\n",
        "They will ask you a question, and your task is to provide the most accurate forecast you can. To do this, you evaluate past data and trends carefully, make use of comparison classes\n",
        "of similar events, take into account base rates about how past events unfolded, and outline the best reasons for and against any particular outcome.\n",
        "You know that great forecasters don't just forecast according to the \"vibe\" of the question and the considerations.\n",
        "Instead, they think about the question in a structured way, recording their reasoning as they go,\n",
        "and they always consider multiple perspectives that usually give different conclusions, which they reason about together.\n",
        "You can't know the future, and the interviewer knows that, so you do not need to hedge your uncertainty, you are simply trying to give\n",
        "the most accurate numbers that will be evaluated when the events later unfold.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 2 is used by forecaster 2, with PROMPT_TEMPLATE appended to the end\n",
        "prompt2 = \"\"\"\n",
        "You are a professional forecaster being tested on your skill. You are being asked a question for which you must provide the most accurate forecast you can.\n",
        "Reason step by step about the best forecast, carefully considering the information you are presented with and the potential that some of the\n",
        "background information and information provided by your research assistant may be out of date or conflicting.\n",
        "You also know that a key forecasting practice is to consider the outside view, thinking carefully about reference classes and base rates and how often similar events\n",
        "have happened in the past.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 3 is used by forecaster 3, with PROMPT_TEMPLATE appended to the end\n",
        "prompt3 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below. You have a keen eye for detail, and know that\n",
        "the resolution criteria and fine print of a question often contain important edge cases that should be considered. You also know that rookie forecasters\n",
        "tend to be underconfident, and so your forecasts should be confident and extremize some of the way toward 1% or 99%. You're also aware that forecasting questions tend\n",
        "to be biased, so when forecasting questions asks about things that would be a departure from the norm or from business as usual, those things tend not to happen.\n",
        "You will use that knowledge to make the best forecast you can, and describe your reasoning step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Forecaster 4 uses prompt 4 parts 1 and 2, with PROMPT_TEMPLATE inserted between part 1 and part 2\n",
        "prompt4part1 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt4part2 = \"\"\"\n",
        "Now that you know what the question asks and some relevant background and research, your job is to make the best forecast you can. You know that examining the reasoning of other\n",
        "forecasters is an excellent way to improve your own forecast. Below I have provided the reasoning from three other forecasters who predicted on the same question.\n",
        "Examine their reasoning and use it to inform your own, using your expertise as a forecaster to assess which reasoning seems strongest and which seems flawed,\n",
        "as well as which reasoning seems to incorporate the most accurate information about base rates and historic reference classes. Construct your own reasoning and forecast,\n",
        "describing your reasoning step by step and incorporating the strongest arguments from the other forecasters in a way that improves your own reasoning. First produce a\n",
        "one sentence summary of the reasoning of each forecaster (repeating the final probability each predicted), then describe your forecast.\n",
        "\n",
        "Forecaster A:\n",
        "[[forecaster1]]\n",
        "\n",
        "Forecaster B:\n",
        "[[forecaster2]]\n",
        "\n",
        "Forecaster C:\n",
        "[[forecaster3]]\n",
        "\"\"\"\n",
        "\n",
        "# PROMPT_TEMPLATE is used with the above prompts to share the details about the question with the LLM.\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Here is the question's fine print that you need to be consistent with in your forecast:\n",
        "[[fine_print]]\n",
        "\n",
        "Here is some background of the question, though note that some of the details may be out of date:\n",
        "[[background]]\n",
        "\n",
        "Your research assistant provides the following information that is likely more up to date:\n",
        "[[summary_report]]\n",
        "\n",
        "Today is [[today]].\n",
        "\n",
        "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2CWVjJ9_tZ6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1cf21377-452a-4fab-edd1-61abd2f8ef92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "It is recommended that you do not edit the below unless you have coding experience.\n",
        "\n",
        "Note that currently the LLM is set to gpt-4o, and this is specified in the code below. This can be changed by advanced users, though changing between OpenAI models is much simpler than changing to a model from a different AI organizations.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k8vtze4SXtR3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmWSCwDLbhFJ"
      },
      "source": [
        "Getting questions (only binaries)\n",
        "\n",
        "Getting them 10 at a time, you can change offset to \"scroll\" through them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9gVXbHIGfOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "06c9a390-ff7e-44f5-9cec-8823b48f8911"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "url = \"https://www.metaculus.com/api2/questions/\"\n",
        "\n",
        "params = {\n",
        "    \"has_group\": \"false\",\n",
        "    \"order_by\": \"-activity\",\n",
        "    \"forecast_type\": \"binary\",\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"status\": \"open\", # can change this to 'closed' for testing where you're not submitting a forecast, otherwise leave as open\n",
        "    \"type\": \"forecast\",\n",
        "    \"title-and-description-only\": \"true\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yioIDa8UsCuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "affb0ff2-a13d-4dd9-c96b-e2bd87e3c2c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def yield_all_questions():\n",
        "  if ANSWER_MANUAL_QUESTION:\n",
        "    yield manual_question_dict\n",
        "    return\n",
        "\n",
        "  limit = 10 # This is a page limit, not question limit\n",
        "  n = 0\n",
        "  new_questions_found = False\n",
        "\n",
        "  while True:\n",
        "    offset = n * limit\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        params={**params, \"limit\": limit, \"offset\": offset},\n",
        "        headers={\"Authorization\": f\"Token {token}\"}\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    questions = response.json().get(\"results\")\n",
        "\n",
        "    # if repredict is true it will skip to the else and predict on all the questions\n",
        "    # if repredict is false it will see if \"my_predictions\" is empty or not for each question, and only predict on questions without a prediction\n",
        "    if not REPREDICT:\n",
        "        for question in questions:\n",
        "            question_id = question['id']\n",
        "\n",
        "            guess_response = requests.get(\n",
        "                f\"{url}{question_id}/\",\n",
        "                headers={\"Authorization\": f\"Token {token}\"}\n",
        "            )\n",
        "            guess_response.raise_for_status()\n",
        "\n",
        "            if not guess_response.json().get(\"my_predictions\"):\n",
        "                new_questions_found = True\n",
        "                yield question\n",
        "    else:\n",
        "        new_questions_found = True\n",
        "        yield from questions\n",
        "\n",
        "    if not response.json().get(\"next\"):\n",
        "      break\n",
        "    n += 1\n",
        "\n",
        "  if not new_questions_found:\n",
        "        print(\"No new questions to predict on.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXyQLerREJGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9bbf2580-cadb-41e7-c976-56f421886901"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def find_number_before_percent(s):\n",
        "    # Use a regular expression to find all numbers followed by a '%'\n",
        "    matches = re.findall(r'(\\d+)%', s)\n",
        "    if matches:\n",
        "        # Return the last number found before a '%'\n",
        "        return int(matches[-1])\n",
        "    else:\n",
        "        # Return None if no number found\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is used to replace the {} keys with [[]], since sometimes the LLM output uses {} when formatting code.\n",
        "\n",
        "def replace_keys(text, key_dict, delimiter='[[', end_delimiter=']]'):\n",
        "    pattern = re.compile(re.escape(delimiter) + '(.*?)' + re.escape(end_delimiter))\n",
        "    def replace(match):\n",
        "        key = match.group(1)\n",
        "        return key_dict.get(key, match.group(0))  # Return the original if key not found\n",
        "    return pattern.sub(replace, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ldAJ5OWBW1mA",
        "outputId": "473eebc4-eaf5-45d5-abfd-3683d8efe729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoV2KKC8l5im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "624be97d-93e3-4777-8798-688f66304daa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def predict(question_id, prediction_percentage):\n",
        "  url = f\"https://www.metaculus.com/api2/questions/{question_id}/predict/\"\n",
        "  response = requests.post(\n",
        "      url,\n",
        "      json={\n",
        "        \"prediction\": float(prediction_percentage) / 100\n",
        "      },\n",
        "      headers={\"Authorization\": f\"Token {token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(f\"Successfully predicted {prediction_percentage} on question {question_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJUGVfHVrms2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6e79d445-555e-42fe-c75f-c6b21acd391e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def formulate_comment(prediction_json):\n",
        "  comment_blocks = []\n",
        "  if \"reasoning_base_rate\" in prediction_json:\n",
        "    comment_blocks.append(\"## Base rate estimation\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_base_rate\"])\n",
        "  if \"reasoning_reference_classes\" in prediction_json:\n",
        "    comment_blocks.append(\"## Reference classes\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_reference_classes\"])\n",
        "  if \"reasoning_other\" in prediction_json:\n",
        "    comment_blocks.append(\"## Additional\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_other\"])\n",
        "  return \"\\n\".join(comment_blocks) if comment_blocks else \"No reasoning provided\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uhKwbzQsKby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bca98ee2-484e-47b7-a6e8-d2ab88c6b7e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def comment(question_id, comment_text):\n",
        "\n",
        "  # for submit_type choose \"S\" to post regular comment and \"N\" for private. Tournament submissions should be private comments.\n",
        "  url = f\"https://www.metaculus.com/api2/comments/\"\n",
        "  response = requests.post(\n",
        "    url,\n",
        "    json={\n",
        "      \"comment_text\":comment_text,\"submit_type\":\"N\",\"include_latest_prediction\":True,\"question\":question_to_forecast['id']\n",
        "    },\n",
        "    headers={\"Authorization\": f\"Token {token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(\"Comment Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2PaTg5H6muR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "25a04b52-c1ff-4c37-f361-0d4aa41ac17d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_perplexity_research(question_id):\n",
        "  url = \"https://ml.metaculus.com/questions-api/perplexity-research-results/\"\n",
        "  headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"X-API-Key\": questions_api_key,\n",
        "    \"content-type\": \"application/json\"\n",
        "  }\n",
        "  params = {\n",
        "    \"question_id\": question_id\n",
        "  }\n",
        "  response = requests.get(url=url, params=params, headers=headers)\n",
        "  if response.status_code == 404:\n",
        "    print(\"No Perplexity research found\")\n",
        "    return \"No results found, please use your own knowledge and judgement to forecast\"\n",
        "  content = response.text\n",
        "\n",
        "  print(\"Generated research from perplexity:\")\n",
        "  print(content)\n",
        "  return content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_pricing(input, output, model):\n",
        "  encoding = tiktoken.encoding_for_model(model)\n",
        "  input_len = len(encoding.encode(input))\n",
        "  output_len = len(encoding.encode(output))\n",
        "\n",
        "\n",
        "  # hard coding for now, maybe make it smarter later\n",
        "  # units of $ per token\n",
        "  gpt4o_input_pricing = 5 / 1_000_000\n",
        "  gpt4o_output_pricing = 15 / 1_000_000\n",
        "\n",
        "  input_cost = input_len * gpt4o_input_pricing\n",
        "  output_cost = output_len * gpt4o_output_pricing\n",
        "  total_cost = input_cost + output_cost\n",
        "\n",
        "  return input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "THGjV1tPd_7Q",
        "outputId": "bbdcc213-a667-4d2d-e8ed-65e893f6d9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_forecast(today, client, question_to_forecast, prompt, summary_report, model):\n",
        "\n",
        "  title = question_to_forecast[\"title\"]\n",
        "  resolution_criteria = question_to_forecast[\"resolution_criteria\"]\n",
        "  background = question_to_forecast[\"description\"]\n",
        "  if question_to_forecast[\"fine_print\"]:\n",
        "    fine_print = question_to_forecast[\"fine_print\"]\n",
        "  else:\n",
        "    fine_print = \"none\"\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  prompt_dict = {\n",
        "      \"title\": title,\n",
        "      \"summary_report\": summary_report,\n",
        "      \"today\": today,\n",
        "      \"background\": background,\n",
        "      \"fine_print\": fine_print,\n",
        "      \"resolution_criteria\": resolution_criteria,\n",
        "  }\n",
        "\n",
        "  prompt_content = replace_keys(prompt, prompt_dict)\n",
        "\n",
        "  print(\"Here is the prompt used:\")\n",
        "  print(prompt_content)\n",
        "  print(\"\")\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt_content\n",
        "      }\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  gpt_text = chat_completion.choices[0].message.content\n",
        "\n",
        "  #estimate cost\n",
        "  input_cost, output_cost, total_cost = estimate_pricing(prompt_content, gpt_text, model)\n",
        "\n",
        "  # Regular expression to find the number following 'Probability: '\n",
        "  probability_match = find_number_before_percent(gpt_text)\n",
        "\n",
        "  # Extract the number if a match is found\n",
        "  if probability_match:\n",
        "      probability = int(probability_match) # int(match.group(1))\n",
        "      print(f\"The extracted probability is: {probability}%\")\n",
        "      #probability = min(max(probability, 3), 97) # To prevent extreme forecasts\n",
        "  else:\n",
        "      probability = None\n",
        "      print(\"No probability found in the text! Skipping!\")\n",
        "  return probability, gpt_text, input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XK4FbnKJb98Q",
        "outputId": "7fc8f3ab-68f4-44f1-8be2-2d334e296b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_perplexity(perplexity_prompt, perplexity_api_key):\n",
        "\n",
        "  from openai import OpenAI\n",
        "\n",
        "  YOUR_API_KEY = perplexity_api_key\n",
        "\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": (\n",
        "              \"You are an artificial intelligence assistant and you need to \"\n",
        "              \"engage in a helpful, detailed, polite conversation with a user.\"\n",
        "          ),\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": (\n",
        "              perplexity_prompt\n",
        "          ),\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  perplexity_client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
        "\n",
        "  # chat completion without streaming\n",
        "  response = perplexity_client.chat.completions.create(\n",
        "      model=PERPLEXITY_MODEL,\n",
        "      messages=messages,\n",
        "  )\n",
        "\n",
        "  content = response.choices[0].message.content\n",
        "\n",
        "  print(\"Generated research from perplexity:\")\n",
        "  print(content)\n",
        "\n",
        "  # get token and cost estimate\n",
        "\n",
        "  # currently using the GPT tokenizer with a 1.3 multiplier. Hacky and wrong, but rough estimate.\n",
        "  # See here for 1.3 factor estimate source: https://github.com/continuedev/continue/issues/878\n",
        "\n",
        "  perplexity_token_pricing = 1/1_000_000\n",
        "  perplexity_cost_fixed = 5/1_000\n",
        "\n",
        "  multiplier = 1.3\n",
        "  encoding = tiktoken.encoding_for_model(OPEN_AI_MODEL)\n",
        "  input_text = perplexity_prompt\n",
        "  output_text = content\n",
        "  input_len = len(encoding.encode(input_text)) * multiplier\n",
        "  output_len = len(encoding.encode(output_text)) * multiplier\n",
        "\n",
        "  input_cost = input_len * perplexity_token_pricing\n",
        "  output_cost = output_len * perplexity_token_pricing\n",
        "  fixed_cost = perplexity_cost_fixed\n",
        "  total_cost = input_cost + output_cost + perplexity_cost_fixed\n",
        "\n",
        "  print(f\"Total perplexity call cost: ${total_cost}\")\n",
        "\n",
        "  return content, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gWXOgDDWx7il",
        "outputId": "245dab67-dca4-4a22-8a8a-258c4199f64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-wVKhWomV2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "27456ced-6654-4f0f-9928-dc1f117bd97b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def clean_gpt_turbo_markdown(text: str) -> str:\n",
        "  match = re.search(r\"```[\\w]+\\s+(.*?)\\s+```\", text, re.DOTALL)\n",
        "  if match:\n",
        "    cleaned_text = match.group(1).strip()\n",
        "  else:\n",
        "    cleaned_text = text\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwc6I64ScFUz"
      },
      "source": [
        "Forecast on all questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C52dUgSG6Pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9da7741e-8bab-45a3-ea00-c7399e57f8ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------------------------------\n",
            "Now Forecasting Question:\n",
            "None Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Getting Perplexity recent research...\n",
            "\n",
            "get_forecast(...):\n",
            "\n",
            "Here is the prompt used:\n",
            "\n",
            "You're being asked the following forecasting question:\n",
            "\n",
            "The question is:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "And it has these specific resolution details:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Fine print:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "To get the latest news that will help you forecast on the question, you need to ask your web search tool one question that would be most valuable to help you forecast\n",
            "on this question. The question should be posed so that the web search tool will provide you with the most recent information, including the latest information on the progress toward\n",
            "the criteria in the forecasting question being met. Please complete the sentence below with the most valuable question to ask:\n",
            "\n",
            "\"What is the most recent news available and prior occurrences related to. . . \"\n",
            "\n",
            "\n",
            "No probability found in the text! Skipping!\n",
            "\n",
            "The completed question posed to perplexity reads: \"the FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss?\"\n",
            "call_perplexity(...)\n",
            "Generated research from perplexity:\n",
            "The FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss is currently ongoing. Here are the key updates and milestones:\n",
            "\n",
            "1. **Phase 2b Results**: Danuglipron demonstrated statistically significant weight reductions in a Phase 2b clinical trial, with mean placebo-adjusted weight reductions ranging from -8% to -13% at 32 weeks and -5% to -9.5% at 26 weeks.\n",
            "\n",
            "2. **Once-Daily Formulation**: Pfizer has selected a preferred once-daily modified release formulation of danuglipron, which showed encouraging pharmacokinetic data. The company plans to conduct dose optimization studies in the second half of 2024 to evaluate multiple doses of this formulation and inform registration-enabling studies.\n",
            "\n",
            "3. **Future Trials**: Pfizer will need to conduct large-scale clinical trials to produce the necessary data to demonstrate the safety, efficacy, and tolerability of danuglipron. These trials will be crucial for submitting the drug for FDA approval.\n",
            "\n",
            "4. **Competitive Landscape**: Danuglipron is part of a growing market for GLP-1 agonists, which is expected to reach $100 billion by the end of the decade. Pfizer is competing with other pharmaceutical companies, such as Novo Nordisk, which has already approved GLP-1 agonist injections like Wegovy and Ozempic.\n",
            "\n",
            "5. **Timeline**: While Pfizer has made significant progress, the FDA approval process is still likely to take time. The company will need to complete the necessary clinical trials and submit the data to the FDA for review before danuglipron can be approved for use in weight loss treatment.\n",
            "\n",
            "In summary, Pfizer's danuglipron is progressing through the clinical trial process, with a focus on a once-daily formulation. The company will need to complete large-scale trials and submit the data to the FDA for approval, which is expected to take place in the future.\n",
            "Total perplexity call cost: $0.0055408\n",
            "Running initial prompt 1\n",
            "get_forecast(...)\n",
            "\n",
            "Here is the prompt used:\n",
            "\n",
            "You are a professional forecaster interviewing for a job. The interviewer is also a professional forecaster, with a strong track record of accurate forecasts of the future.\n",
            "They will ask you a question, and your task is to provide the most accurate forecast you can. To do this, you evaluate past data and trends carefully, make use of comparison classes\n",
            "of similar events, take into account base rates about how past events unfolded, and outline the best reasons for and against any particular outcome.\n",
            "You know that great forecasters don't just forecast according to the \"vibe\" of the question and the considerations.\n",
            "Instead, they think about the question in a structured way, recording their reasoning as they go,\n",
            "and they always consider multiple perspectives that usually give different conclusions, which they reason about together.\n",
            "You can't know the future, and the interviewer knows that, so you do not need to hedge your uncertainty, you are simply trying to give\n",
            "the most accurate numbers that will be evaluated when the events later unfold.\n",
            "\n",
            "\n",
            "\n",
            "The question is:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is the question's fine print that you need to be consistent with in your forecast:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is some background of the question, though note that some of the details may be out of date:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Your research assistant provides the following information that is likely more up to date:\n",
            "The FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss is currently ongoing. Here are the key updates and milestones:\n",
            "\n",
            "1. **Phase 2b Results**: Danuglipron demonstrated statistically significant weight reductions in a Phase 2b clinical trial, with mean placebo-adjusted weight reductions ranging from -8% to -13% at 32 weeks and -5% to -9.5% at 26 weeks.\n",
            "\n",
            "2. **Once-Daily Formulation**: Pfizer has selected a preferred once-daily modified release formulation of danuglipron, which showed encouraging pharmacokinetic data. The company plans to conduct dose optimization studies in the second half of 2024 to evaluate multiple doses of this formulation and inform registration-enabling studies.\n",
            "\n",
            "3. **Future Trials**: Pfizer will need to conduct large-scale clinical trials to produce the necessary data to demonstrate the safety, efficacy, and tolerability of danuglipron. These trials will be crucial for submitting the drug for FDA approval.\n",
            "\n",
            "4. **Competitive Landscape**: Danuglipron is part of a growing market for GLP-1 agonists, which is expected to reach $100 billion by the end of the decade. Pfizer is competing with other pharmaceutical companies, such as Novo Nordisk, which has already approved GLP-1 agonist injections like Wegovy and Ozempic.\n",
            "\n",
            "5. **Timeline**: While Pfizer has made significant progress, the FDA approval process is still likely to take time. The company will need to complete the necessary clinical trials and submit the data to the FDA for review before danuglipron can be approved for use in weight loss treatment.\n",
            "\n",
            "In summary, Pfizer's danuglipron is progressing through the clinical trial process, with a focus on a once-daily formulation. The company will need to complete large-scale trials and submit the data to the FDA for approval, which is expected to take place in the future.\n",
            "\n",
            "Today is 2024-07-19.\n",
            "\n",
            "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
            "\n",
            "\n",
            "The extracted probability is: 45%\n",
            "Output Reasoning:\n",
            "1. **Historical data**\n",
            "\n",
            "   Looking at historical data, typically, less than 14% of all drugs in phase 1 clinical trials successfully navigate their way through Phases 2, 3, and into FDA approval (source: Biotech Primer). But, given that Pfizer's GLP-1 trial agent danuglipron is currently on phase 2b and has shown satisfactory results, the probability of failure at this stage should be significantly lower. Therefore, we will increase our base probability a bit taking into account Pfizerâ€™s GLP-1 is past phase 1.\n",
            "\n",
            "2. **Positive results from Phase 2b trials**\n",
            "\n",
            "   The results from Phase 2b trials were favorable with a significant reduction in weight, which augurs well for the drug's potential approval. The weight reductions ranged from -8% to -13% at 32 weeks, which seems promising.\n",
            "\n",
            "3. **Formulation & Future trials**\n",
            "\n",
            "   Pfizer has selected a once-daily release formula for danuglipron, which reflects positively on the predictability of its effects. However, large-scale clinical trials must still be conducted. The results from these trials will play a critical role in the approval process.\n",
            "\n",
            "4. **Competitive landscape**\n",
            "\n",
            "   The GLP-1 agonists market is growing and expected to reach $100 billion by the end of the decade. This could mean increased competition, but also a potentially robust demand for effective solutions like danuglipron. \n",
            "\n",
            "5. **Timeline considerations**\n",
            "\n",
            "   Although the drug has made significant progress, the process from here will still require considerable time. Pfizer still has to conduct large-scale trials, analyze the data, prepare the registration submission, and wait for FDA approval.\n",
            "\n",
            "6. **Additional consideration**\n",
            "\n",
            "   As a final thought, Pfizer is a huge company with significant resources, and they have a strong track record of getting drugs approved by the FDA. \n",
            "\n",
            "\n",
            "Given all these factors, it seems that the drug has a higher than average chance of getting approved. Balancing all these factors, my estimate would be:\n",
            "\n",
            "Probability: 45%.\n",
            "\n",
            "This reflects an optimistic adjustment from the historical average success rate after phase 2 trials, reflecting the promising data so far, the existing competition, Pfizerâ€™s reputation for successfully bringing drugs to market, but also the number of trials that still need to be carried out successfully, and the inherent uncertainty in such predictions. Remember, this is just a forecast and real-world circumstances may change rapidly and impact this estimate.\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 2\n",
            "get_forecast(...)\n",
            "\n",
            "Here is the prompt used:\n",
            "\n",
            "You are a professional forecaster being tested on your skill. You are being asked a question for which you must provide the most accurate forecast you can.\n",
            "Reason step by step about the best forecast, carefully considering the information you are presented with and the potential that some of the\n",
            "background information and information provided by your research assistant may be out of date or conflicting.\n",
            "You also know that a key forecasting practice is to consider the outside view, thinking carefully about reference classes and base rates and how often similar events\n",
            "have happened in the past.\n",
            "\n",
            "\n",
            "\n",
            "The question is:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is the question's fine print that you need to be consistent with in your forecast:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is some background of the question, though note that some of the details may be out of date:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Your research assistant provides the following information that is likely more up to date:\n",
            "The FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss is currently ongoing. Here are the key updates and milestones:\n",
            "\n",
            "1. **Phase 2b Results**: Danuglipron demonstrated statistically significant weight reductions in a Phase 2b clinical trial, with mean placebo-adjusted weight reductions ranging from -8% to -13% at 32 weeks and -5% to -9.5% at 26 weeks.\n",
            "\n",
            "2. **Once-Daily Formulation**: Pfizer has selected a preferred once-daily modified release formulation of danuglipron, which showed encouraging pharmacokinetic data. The company plans to conduct dose optimization studies in the second half of 2024 to evaluate multiple doses of this formulation and inform registration-enabling studies.\n",
            "\n",
            "3. **Future Trials**: Pfizer will need to conduct large-scale clinical trials to produce the necessary data to demonstrate the safety, efficacy, and tolerability of danuglipron. These trials will be crucial for submitting the drug for FDA approval.\n",
            "\n",
            "4. **Competitive Landscape**: Danuglipron is part of a growing market for GLP-1 agonists, which is expected to reach $100 billion by the end of the decade. Pfizer is competing with other pharmaceutical companies, such as Novo Nordisk, which has already approved GLP-1 agonist injections like Wegovy and Ozempic.\n",
            "\n",
            "5. **Timeline**: While Pfizer has made significant progress, the FDA approval process is still likely to take time. The company will need to complete the necessary clinical trials and submit the data to the FDA for review before danuglipron can be approved for use in weight loss treatment.\n",
            "\n",
            "In summary, Pfizer's danuglipron is progressing through the clinical trial process, with a focus on a once-daily formulation. The company will need to complete large-scale trials and submit the data to the FDA for approval, which is expected to take place in the future.\n",
            "\n",
            "Today is 2024-07-19.\n",
            "\n",
            "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
            "\n",
            "\n",
            "The extracted probability is: 65%\n",
            "Output Reasoning:\n",
            "First, I will consider the evidence from the Phase 2b Clinical Trial. The weight reduction percentages indicate that danuglipron has a statistically significant impact on weight loss. This positive trial result increases the likelihood of FDA approval, especially considering the FDA's past approval of weight-loss drugs with similar efficacy levels.\n",
            "\n",
            "Secondly, the chosen once-daily modified release formulation indicates a user-friendly regimen that can improve patient adherence, which positively impacts the approval chances. Moreover, Pfizer's plan to conduct dose optimization studies suggests careful preparation for Phase 3 trials, another positive sign.\n",
            "\n",
            "Thirdly, the need for large-scale clinical trials is a standard requirement for all new drugs. As long as these trials continue to display the safety, efficacy, and tolerability of danuglipron, this should not hamper the FDA approval process.\n",
            "\n",
            "Fourthly, considering the competitive landscape, the fact that other GLP-1 agonists have been approved by the FDA (like Novo Nordisk's Wegovy and Ozempic) shows the regulatory bodyâ€™s willingness to approve this drug class for weight loss. This supports a higher approval probability for danuglipron.\n",
            "\n",
            "However, the time factor may play a significant role. It's mid-2024 now, and large-scale trials plus FDA review might take 3-4 years. The tight timeline until January 1, 2028, leaves little room for unexpected delays, which adds some uncertainty.\n",
            "\n",
            "Next, Iâ€™ll consider the outside view. According to FDA data, around 85-90% of drugs entering Phase 3 trials will seek FDA approval and about 56% of those gain approval. Recognizing that danuglipron is a GLP-1 agonist, a drug class for which there is precedent for FDA approval, the rates might be somewhat higher than the average.\n",
            "\n",
            "Weighing all these factors, the positive clinical trial results, the precedence of FDA approval for similar drugs, plus the market potential of the GLP-1 agonists, are encouraging. However, the tight timeline and inherent risks related to large-scale trials add a level of uncertainty.\n",
            "\n",
            "Probability: 65%\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 3\n",
            "get_forecast(...)\n",
            "\n",
            "Here is the prompt used:\n",
            "\n",
            "You are a professional forecaster trying your best to produce an accurate forecast for the question below. You have a keen eye for detail, and know that\n",
            "the resolution criteria and fine print of a question often contain important edge cases that should be considered. You also know that rookie forecasters\n",
            "tend to be underconfident, and so your forecasts should be confident and extremize some of the way toward 1% or 99%. You're also aware that forecasting questions tend\n",
            "to be biased, so when forecasting questions asks about things that would be a departure from the norm or from business as usual, those things tend not to happen.\n",
            "You will use that knowledge to make the best forecast you can, and describe your reasoning step by step.\n",
            "\n",
            "\n",
            "\n",
            "The question is:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is the question's fine print that you need to be consistent with in your forecast:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is some background of the question, though note that some of the details may be out of date:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Your research assistant provides the following information that is likely more up to date:\n",
            "The FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss is currently ongoing. Here are the key updates and milestones:\n",
            "\n",
            "1. **Phase 2b Results**: Danuglipron demonstrated statistically significant weight reductions in a Phase 2b clinical trial, with mean placebo-adjusted weight reductions ranging from -8% to -13% at 32 weeks and -5% to -9.5% at 26 weeks.\n",
            "\n",
            "2. **Once-Daily Formulation**: Pfizer has selected a preferred once-daily modified release formulation of danuglipron, which showed encouraging pharmacokinetic data. The company plans to conduct dose optimization studies in the second half of 2024 to evaluate multiple doses of this formulation and inform registration-enabling studies.\n",
            "\n",
            "3. **Future Trials**: Pfizer will need to conduct large-scale clinical trials to produce the necessary data to demonstrate the safety, efficacy, and tolerability of danuglipron. These trials will be crucial for submitting the drug for FDA approval.\n",
            "\n",
            "4. **Competitive Landscape**: Danuglipron is part of a growing market for GLP-1 agonists, which is expected to reach $100 billion by the end of the decade. Pfizer is competing with other pharmaceutical companies, such as Novo Nordisk, which has already approved GLP-1 agonist injections like Wegovy and Ozempic.\n",
            "\n",
            "5. **Timeline**: While Pfizer has made significant progress, the FDA approval process is still likely to take time. The company will need to complete the necessary clinical trials and submit the data to the FDA for review before danuglipron can be approved for use in weight loss treatment.\n",
            "\n",
            "In summary, Pfizer's danuglipron is progressing through the clinical trial process, with a focus on a once-daily formulation. The company will need to complete large-scale trials and submit the data to the FDA for approval, which is expected to take place in the future.\n",
            "\n",
            "Today is 2024-07-19.\n",
            "\n",
            "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
            "\n",
            "\n",
            "The extracted probability is: 70%\n",
            "Output Reasoning:\n",
            "Step 1: Understanding the Question\n",
            "\n",
            "The first step to accurate forecasting is understanding the question and all of its components fully. Here, we are trying to forecast whether Pfizer's GLP-1 trial agent Danuglipron will be approved by the FDA for weight loss by January 1, 2028. \n",
            "\n",
            "Step 2: Gathering Information\n",
            "\n",
            "Next, I gather all relevant information regarding the question. Based on the update from the research assistant, Danuglipron has shown promising results in Phase 2b clinical trials and Johnson & Johnson plans to conduct dose optimization studies in the second half of 2024 for its once-daily formulation. Large-scale clinical trials still need to be conducted for FDA approval. \n",
            "\n",
            "Step 3: Considering Timeline and Factors\n",
            "\n",
            "Given that today's date is July 19, 2024, Pfizer has about three years and five months to gain FDA approval for Danuglipron by the deadline stated in the question (January 1, 2028). The clinical trial process, FDA review, and approval can be lengthy and often unpredictable, which adds a level of uncertainty to the forecast. However, the positive results from the Phase 2b trial and the promising once-daily formulation suggest that the drug has a good chance. In the competitive landscape of GLP-1 agonists, Pfizer will likely strive for prompt completion and submission of all required studies and data for the FDA approval process.\n",
            "\n",
            "Step 4: Forecasting\n",
            "\n",
            "Considering all factors, Danuglipron has a good chance of gaining FDA approval by the 2028 deadline. It is in a promising class of drugs in a market set to be worth $100 billion by the end of the decade. The drug has demonstrated statistically significant results already, which bodes well for future trials. \n",
            "\n",
            "However, the potentially extended timeline for large scale trials, and additional, often lengthy, process of FDA review and approval, introduces some uncertainty into the forecast. The competitive landscape also suggests that there may well be hurdles to approval such as need for comparison studies and delays due to competitors' activities. \n",
            "\n",
            "With these factors in mind, considering the approximate three and a half year timeline, the process that still needs to take place, the promising trial results thus far, and the growing albeit competitive market, I would predict a strong probability of approval. \n",
            "\n",
            "Final answer: Probability: 70%\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "+++++++++++ FINAL PROMPT (4) +++++++++++++++++\n",
            "\n",
            "Here is the prompt used:\n",
            "\n",
            "You are a professional forecaster trying your best to produce an accurate forecast for the question below.\n",
            "\n",
            "\n",
            "\n",
            "The question is:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is the question's fine print that you need to be consistent with in your forecast:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Here is some background of the question, though note that some of the details may be out of date:\n",
            "Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\n",
            "\n",
            "Your research assistant provides the following information that is likely more up to date:\n",
            "The FDA approval process of Pfizer's GLP-1 trial agent danuglipron for weight loss is currently ongoing. Here are the key updates and milestones:\n",
            "\n",
            "1. **Phase 2b Results**: Danuglipron demonstrated statistically significant weight reductions in a Phase 2b clinical trial, with mean placebo-adjusted weight reductions ranging from -8% to -13% at 32 weeks and -5% to -9.5% at 26 weeks.\n",
            "\n",
            "2. **Once-Daily Formulation**: Pfizer has selected a preferred once-daily modified release formulation of danuglipron, which showed encouraging pharmacokinetic data. The company plans to conduct dose optimization studies in the second half of 2024 to evaluate multiple doses of this formulation and inform registration-enabling studies.\n",
            "\n",
            "3. **Future Trials**: Pfizer will need to conduct large-scale clinical trials to produce the necessary data to demonstrate the safety, efficacy, and tolerability of danuglipron. These trials will be crucial for submitting the drug for FDA approval.\n",
            "\n",
            "4. **Competitive Landscape**: Danuglipron is part of a growing market for GLP-1 agonists, which is expected to reach $100 billion by the end of the decade. Pfizer is competing with other pharmaceutical companies, such as Novo Nordisk, which has already approved GLP-1 agonist injections like Wegovy and Ozempic.\n",
            "\n",
            "5. **Timeline**: While Pfizer has made significant progress, the FDA approval process is still likely to take time. The company will need to complete the necessary clinical trials and submit the data to the FDA for review before danuglipron can be approved for use in weight loss treatment.\n",
            "\n",
            "In summary, Pfizer's danuglipron is progressing through the clinical trial process, with a focus on a once-daily formulation. The company will need to complete large-scale trials and submit the data to the FDA for approval, which is expected to take place in the future.\n",
            "\n",
            "Today is 2024-07-19.\n",
            "\n",
            "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
            "\n",
            "Now that you know what the question asks and some relevant background and research, your job is to make the best forecast you can. You know that examining the reasoning of other\n",
            "forecasters is an excellent way to improve your own forecast. Below I have provided the reasoning from three other forecasters who predicted on the same question.\n",
            "Examine their reasoning and use it to inform your own, using your expertise as a forecaster to assess which reasoning seems strongest and which seems flawed,\n",
            "as well as which reasoning seems to incorporate the most accurate information about base rates and historic reference classes. Construct your own reasoning and forecast,\n",
            "describing your reasoning step by step and incorporating the strongest arguments from the other forecasters in a way that improves your own reasoning. First produce a\n",
            "one sentence summary of the reasoning of each forecaster (repeating the final probability each predicted), then describe your forecast.\n",
            "\n",
            "Forecaster A:\n",
            "1. **Historical data**\n",
            "\n",
            "   Looking at historical data, typically, less than 14% of all drugs in phase 1 clinical trials successfully navigate their way through Phases 2, 3, and into FDA approval (source: Biotech Primer). But, given that Pfizer's GLP-1 trial agent danuglipron is currently on phase 2b and has shown satisfactory results, the probability of failure at this stage should be significantly lower. Therefore, we will increase our base probability a bit taking into account Pfizerâ€™s GLP-1 is past phase 1.\n",
            "\n",
            "2. **Positive results from Phase 2b trials**\n",
            "\n",
            "   The results from Phase 2b trials were favorable with a significant reduction in weight, which augurs well for the drug's potential approval. The weight reductions ranged from -8% to -13% at 32 weeks, which seems promising.\n",
            "\n",
            "3. **Formulation & Future trials**\n",
            "\n",
            "   Pfizer has selected a once-daily release formula for danuglipron, which reflects positively on the predictability of its effects. However, large-scale clinical trials must still be conducted. The results from these trials will play a critical role in the approval process.\n",
            "\n",
            "4. **Competitive landscape**\n",
            "\n",
            "   The GLP-1 agonists market is growing and expected to reach $100 billion by the end of the decade. This could mean increased competition, but also a potentially robust demand for effective solutions like danuglipron. \n",
            "\n",
            "5. **Timeline considerations**\n",
            "\n",
            "   Although the drug has made significant progress, the process from here will still require considerable time. Pfizer still has to conduct large-scale trials, analyze the data, prepare the registration submission, and wait for FDA approval.\n",
            "\n",
            "6. **Additional consideration**\n",
            "\n",
            "   As a final thought, Pfizer is a huge company with significant resources, and they have a strong track record of getting drugs approved by the FDA. \n",
            "\n",
            "\n",
            "Given all these factors, it seems that the drug has a higher than average chance of getting approved. Balancing all these factors, my estimate would be:\n",
            "\n",
            "Probability: 45%.\n",
            "\n",
            "This reflects an optimistic adjustment from the historical average success rate after phase 2 trials, reflecting the promising data so far, the existing competition, Pfizerâ€™s reputation for successfully bringing drugs to market, but also the number of trials that still need to be carried out successfully, and the inherent uncertainty in such predictions. Remember, this is just a forecast and real-world circumstances may change rapidly and impact this estimate.\n",
            "\n",
            "Forecaster B:\n",
            "First, I will consider the evidence from the Phase 2b Clinical Trial. The weight reduction percentages indicate that danuglipron has a statistically significant impact on weight loss. This positive trial result increases the likelihood of FDA approval, especially considering the FDA's past approval of weight-loss drugs with similar efficacy levels.\n",
            "\n",
            "Secondly, the chosen once-daily modified release formulation indicates a user-friendly regimen that can improve patient adherence, which positively impacts the approval chances. Moreover, Pfizer's plan to conduct dose optimization studies suggests careful preparation for Phase 3 trials, another positive sign.\n",
            "\n",
            "Thirdly, the need for large-scale clinical trials is a standard requirement for all new drugs. As long as these trials continue to display the safety, efficacy, and tolerability of danuglipron, this should not hamper the FDA approval process.\n",
            "\n",
            "Fourthly, considering the competitive landscape, the fact that other GLP-1 agonists have been approved by the FDA (like Novo Nordisk's Wegovy and Ozempic) shows the regulatory bodyâ€™s willingness to approve this drug class for weight loss. This supports a higher approval probability for danuglipron.\n",
            "\n",
            "However, the time factor may play a significant role. It's mid-2024 now, and large-scale trials plus FDA review might take 3-4 years. The tight timeline until January 1, 2028, leaves little room for unexpected delays, which adds some uncertainty.\n",
            "\n",
            "Next, Iâ€™ll consider the outside view. According to FDA data, around 85-90% of drugs entering Phase 3 trials will seek FDA approval and about 56% of those gain approval. Recognizing that danuglipron is a GLP-1 agonist, a drug class for which there is precedent for FDA approval, the rates might be somewhat higher than the average.\n",
            "\n",
            "Weighing all these factors, the positive clinical trial results, the precedence of FDA approval for similar drugs, plus the market potential of the GLP-1 agonists, are encouraging. However, the tight timeline and inherent risks related to large-scale trials add a level of uncertainty.\n",
            "\n",
            "Probability: 65%\n",
            "\n",
            "Forecaster C:\n",
            "Step 1: Understanding the Question\n",
            "\n",
            "The first step to accurate forecasting is understanding the question and all of its components fully. Here, we are trying to forecast whether Pfizer's GLP-1 trial agent Danuglipron will be approved by the FDA for weight loss by January 1, 2028. \n",
            "\n",
            "Step 2: Gathering Information\n",
            "\n",
            "Next, I gather all relevant information regarding the question. Based on the update from the research assistant, Danuglipron has shown promising results in Phase 2b clinical trials and Johnson & Johnson plans to conduct dose optimization studies in the second half of 2024 for its once-daily formulation. Large-scale clinical trials still need to be conducted for FDA approval. \n",
            "\n",
            "Step 3: Considering Timeline and Factors\n",
            "\n",
            "Given that today's date is July 19, 2024, Pfizer has about three years and five months to gain FDA approval for Danuglipron by the deadline stated in the question (January 1, 2028). The clinical trial process, FDA review, and approval can be lengthy and often unpredictable, which adds a level of uncertainty to the forecast. However, the positive results from the Phase 2b trial and the promising once-daily formulation suggest that the drug has a good chance. In the competitive landscape of GLP-1 agonists, Pfizer will likely strive for prompt completion and submission of all required studies and data for the FDA approval process.\n",
            "\n",
            "Step 4: Forecasting\n",
            "\n",
            "Considering all factors, Danuglipron has a good chance of gaining FDA approval by the 2028 deadline. It is in a promising class of drugs in a market set to be worth $100 billion by the end of the decade. The drug has demonstrated statistically significant results already, which bodes well for future trials. \n",
            "\n",
            "However, the potentially extended timeline for large scale trials, and additional, often lengthy, process of FDA review and approval, introduces some uncertainty into the forecast. The competitive landscape also suggests that there may well be hurdles to approval such as need for comparison studies and delays due to competitors' activities. \n",
            "\n",
            "With these factors in mind, considering the approximate three and a half year timeline, the process that still needs to take place, the promising trial results thus far, and the growing albeit competitive market, I would predict a strong probability of approval. \n",
            "\n",
            "Final answer: Probability: 70%\n",
            "\n",
            "\n",
            "The extracted probability is: 65%\n",
            "\n",
            "  *This forecast is produced from four separate prompts. The first three produce independent forecasts and reasoning using different prompts, and the fourth reads the reasoning and forecasts fo the first three and produces its own forecast. Then a weighted forecast is produced from the four forecasts as described below. The reasoning shown is that of the fourth forecaster or \"Summary Forecaster\". See [the code](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?usp=sharing) for more info on the prompts used.*\n",
            "\n",
            "  * *Model used: gpt-4*\n",
            "  * *Weighted formula: (0.2)(Forecaster A) + (0.2)(Forecaster B) + (0.2)(Forecaster C) + (0.4)(Summary Forecaster)*\n",
            "  * *Estimated cost of model calls based on tokens (excluding Perplexity info used): $0.051*\n",
            "  * ***Final weighted forecast: 62%***\n",
            "\n",
            "  ---\n",
            "\n",
            "  \n",
            "Output Reasoning:\n",
            "Forecaster A uses historical data, along with promising results from the Phase 2b trials, chosen formulation, and future trials requirement, to give a lower probability of approval (45%). They balance this with the recognition of Pfizer's reputation and potential market size. \n",
            "\n",
            "Forecaster B considers the promising results from Phase 2b trials, the indications of careful preparation for Phase 3 trials, the fact that other GLP-1 agonists have been approved, and the expected timeline to give a probability of approval of 65%. They balance these factors against the tight timeline and inherent risks in large-scale trials. \n",
            "\n",
            "Forecaster C applies a step-by-step approach, from understanding the question, to gathering information, to considering timelines and factors, to finally formulating a forecast. They take into account the promising Phase 2b trial results, the competitive but lucrative market for GLP-1 agonists, and the timeline, giving a probability of approval of 70%.\n",
            "\n",
            "My Forecast:\n",
            "Drawing from the strong arguments put forward by all three forecasters, it is clear that promising Phase 2b trials, the chosen once-daily formulation, and the competitiveness but potential high returns of the market all increase the likelihood of danuglipron's approval. The pivotal role of future large-scale clinical trials in the approval process is also crucial and it is assumed that Pfizer would commit significant resources to ensure success. \n",
            "\n",
            "However, the timeline for approval is tight and unexpected delays could impact the chances of approval within the stipulated timeframe. Taking these factors into account and considering Pfizer's reputation and historical success rate, my forecast veers towards the more optimistic estimates of forecaster B and C. \n",
            "\n",
            "However, given the uncertainty of large-scale clinical trials and the potential for delays in the approval process, I will place my forecast slightly lower than the highest estimate.\n",
            "\n",
            "Therefore, my final estimate is: Probability: 65%. This estimation reflects the potential for danuglipron's approval based on the promising results in Phase 2b trials, the precedents set by approval of other GLP-1 agonists, and Pfizer's reputability. However, the complexity and uncertainty that round out the clinical trials and the approval process leave room for variability in this prediction.\n",
            "\n",
            "FINAL WEIGHTED FORECAST:\n",
            "62%\n",
            "\n",
            "Overall cost was: $0.05068500000000001\n",
            "\n",
            "################ NEXT QUESTION #################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "client = OpenAI()\n",
        "model = OPEN_AI_MODEL\n",
        "ENABLE_PERPLEXITY_RESEARCH = False  # Previously this could be set to True to get and use pre-computed Perplexity research results for the question, set to False otherwise.\n",
        "# However, Metaculus no longer supports pre-computed Perplexity research, so it has been permanently set to False here to skip over that setp.\n",
        "\n",
        "promptset = [prompt1 + PROMPT_TEMPLATE, prompt2 + PROMPT_TEMPLATE, prompt3 + PROMPT_TEMPLATE]\n",
        "\n",
        "forecasted_count = 0\n",
        "\n",
        "for question_to_forecast in yield_all_questions():\n",
        "  if forecasted_count >= MAX_QUESTIONS_TO_FORECAST:\n",
        "    break\n",
        "  if QUESTION_IDS_TO_FORECAST is not None and question_to_forecast[\"id\"] not in QUESTION_IDS_TO_FORECAST:\n",
        "    continue\n",
        "\n",
        "  print (\"\")\n",
        "  print(\"-------------------------------------------\")\n",
        "  print(\"Now Forecasting Question:\")\n",
        "  print(question_to_forecast[\"id\"], question_to_forecast[\"title\"])\n",
        "  print(\"\")\n",
        "\n",
        "  #define perplexity research to use\n",
        "  perplexity_total_cost = \"N/A\"\n",
        "\n",
        "  if ENABLE_PERPLEXITY_RESEARCH:\n",
        "    summary_report = get_perplexity_research(question_to_forecast[\"id\"])\n",
        "  else:\n",
        "    #summary_report = \"No results found, please use your own knowledge and judgement to forecast\"\n",
        "    summary_report = \"\"\n",
        "\n",
        "  # set summary_report to the perplexity recent search if enabled\n",
        "  if USE_PERPLEXITY_RECENT:\n",
        "    print(\"Getting Perplexity recent research...\")\n",
        "    print (\"\")\n",
        "    print(\"get_forecast(...):\")\n",
        "    #get prompt completion for use with perplexity\n",
        "    probability, perplexity_recent_prompt, completion_input_cost, completion_output_cost, completion_total_cost = get_forecast(today, client, question_to_forecast, LLM_question_completion, summary_report, model)\n",
        "    print(\"\")\n",
        "\n",
        "    print(f\"The completed question posed to perplexity reads: {perplexity_recent_prompt}\")\n",
        "    #get recent news from perplexity\n",
        "    print(\"call_perplexity(...)\")\n",
        "    perplexity_content, perplexity_cost = call_perplexity(perplexity_recent_prompt, perplexity_api_key)\n",
        "\n",
        "    summary_report = perplexity_content\n",
        "    perplexity_total_cost = completion_total_cost + perplexity_cost\n",
        "\n",
        "  # need to iterate through prompts here\n",
        "  all_forecasts = []\n",
        "  overall_cost = 0\n",
        "\n",
        "  i = 0\n",
        "  for prompt in promptset:\n",
        "    i+=1\n",
        "    print(\"Running initial prompt %s\" % i)\n",
        "    print(\"get_forecast(...)\")\n",
        "    probability, gpt_text, input_cost, output_cost, total_cost = get_forecast(today, client, question_to_forecast, prompt, summary_report, model)\n",
        "    all_forecasts.append((probability, gpt_text, input_cost, output_cost, total_cost))\n",
        "    overall_cost += total_cost\n",
        "    print(f\"Output Reasoning:\")\n",
        "    print(gpt_text)\n",
        "    #print(f\"Input cost: ${input_cost}\")\n",
        "    #print(f\"Output cost: ${output_cost}\")\n",
        "    #print(f\"Total cost: ${total_cost}\")\n",
        "    #print(f\"Perplexity search costs (including LLM prompt completion): ${completion_total_cost + perplexity_cost}\")\n",
        "    print(\"\")\n",
        "    print(\"~~~~ NEXT PROMPT ~~~~\")\n",
        "    print(\"\")\n",
        "\n",
        "  prompt4part2_dict = {\n",
        "      \"forecaster1\": all_forecasts[0][1],\n",
        "      \"forecaster2\": all_forecasts[1][1],\n",
        "      \"forecaster3\": all_forecasts[2][1],\n",
        "  }\n",
        "\n",
        "  formatted_prompt4part2 = replace_keys(prompt4part2, prompt4part2_dict)\n",
        "\n",
        "  print(\"+++++++++++ FINAL PROMPT (4) +++++++++++++++++\")\n",
        "\n",
        "  prompt4 = prompt4part1 + PROMPT_TEMPLATE + formatted_prompt4part2\n",
        "\n",
        "  probability, gpt_text, input_cost, output_cost, total_cost = get_forecast(today, client, question_to_forecast, prompt4, summary_report, model)\n",
        "\n",
        "  forecaster1_weight = 0.2\n",
        "  forecaster2_weight = 0.2\n",
        "  forecaster3_weight = 0.2\n",
        "  forecaster4_weight = 0.4\n",
        "\n",
        "  weighted_forecast = forecaster1_weight*float(all_forecasts[0][0]) + forecaster2_weight*float(all_forecasts[1][0]) + forecaster3_weight*float(all_forecasts[2][0]) + forecaster4_weight*float(probability)\n",
        "  weighted_forecast = int(weighted_forecast)\n",
        "  overall_cost = overall_cost + total_cost\n",
        "\n",
        "  #create summary strings for comments:\n",
        "  header_string = f\"\"\"\n",
        "  *This forecast is produced from four separate prompts. The first three produce independent forecasts and reasoning using different prompts, and the fourth reads the reasoning and forecasts fo the first three and produces its own forecast. Then a weighted forecast is produced from the four forecasts as described below. The reasoning shown is that of the fourth forecaster or \"Summary Forecaster\". See [the code](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?usp=sharing) for more info on the prompts used.*\n",
        "\n",
        "  * *Model used: {model}*\n",
        "  * *Weighted formula: ({forecaster1_weight})(Forecaster A) + ({forecaster2_weight})(Forecaster B) + ({forecaster3_weight})(Forecaster C) + ({forecaster4_weight})(Summary Forecaster)*\n",
        "  * *Estimated cost of model calls based on tokens (excluding Perplexity info used): ${round(overall_cost,3)}*\n",
        "  * ***Final weighted forecast: {weighted_forecast}%***\n",
        "\n",
        "  ---\n",
        "\n",
        "  \"\"\"\n",
        "  print(header_string)\n",
        "\n",
        "  forecasted_count += 1\n",
        "  if SUBMIT_FORECASTS and weighted_forecast is not None:\n",
        "    predict(question_to_forecast[\"id\"], float(weighted_forecast))\n",
        "    comment(question_to_forecast[\"id\"], header_string + \"PERPLEXITY\\n\\n\" + summary_report + \"\\n\\n---\\n\\n\" + \"GPT\\n\\n\" + gpt_text)\n",
        "\n",
        "  print(f\"Output Reasoning:\")\n",
        "  print(gpt_text)\n",
        "  print(\"\")\n",
        "  print(\"FINAL WEIGHTED FORECAST:\")\n",
        "  print(f\"{weighted_forecast}%\")\n",
        "  print(\"\")\n",
        "  print(f\"Overall cost was: ${overall_cost}\")\n",
        "  print(\"\")\n",
        "  print(\"################ NEXT QUESTION #################\")\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qfSjn0L_8I3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}