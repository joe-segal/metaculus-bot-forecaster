{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joe-segal/metaculus-bot-forecaster/blob/main/JMS_Metaculus_Bot_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Forecasting Bot\n",
        "*Created by Kirill and Tom, revised by Ryan*\n",
        "\n",
        "The code below is used for making LLM-powered forecasts in Metaculus' [AI benchmarking competition](https://www.metaculus.com/project/ai-benchmarking-pilot/).\n",
        "\n",
        "Specifically, it does the following:\n",
        "\n",
        "* Gets questions from the project page using the Metaculus API\n",
        "* Gets four separate forecasts from the LLM, three independently and the fourth assessing the reasoning of the first three and producing its own.\n",
        "* Predicts on the Metaculus questions and shares a comment describing the reasoning of the fourth LLM forecast.\n",
        "\n",
        "Features and options:\n",
        "\n",
        "* Allows you to choose whether it repredicts on questions it's already forecasted on or ignores them.\n",
        "* Allows for the use of [Perplexity search](https://www.perplexity.ai/) for additional research, using a prompt formed by an LLM.\n",
        "    * *Previously this allowed for the use of pre-computed Perpelxity results, but this is no longer supported by Metaculus.*\n",
        "* Can be used with an automated workflow via Github actions to monitor the project for new open questions and make forecasts when there are some\n",
        "    * See [this Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for how to set this up"
      ],
      "metadata": {
        "id": "zMlSOSdSYCds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸš¨ðŸš¨ðŸš¨ Warning ðŸš¨ðŸš¨ðŸš¨\n",
        "\n",
        "**You are responsible for monitoring the costs of your implementation, especially if using the automated Github workflow. Cost estimates computed by this notebook are rough estimates only, make sure to check and monitor how much you are spending and the funds in your relevant accounts.**"
      ],
      "metadata": {
        "id": "TZ5X6zf7bYT-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqR47EYbh6p"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "### Make a Metaculus Bot Account\n",
        "The first step will be to make a Metaculus bot account. Instructions for how to do this have likely already been provided to you, either via a page on Metaculus or at an event.\n",
        "\n",
        "### Secrets and Tokens\n",
        "\n",
        "You need to set secrets 1) and 2) in order to make forecasts. Secrets 3) and 4) are necessary if you will be using Perplexity research.\n",
        "\n",
        "1) METACULUS_TOKEN (you can find it or create it here - https://www.metaculus.com/admin/authtoken/tokenproxy/, or ask Metaculus to share it with you).\n",
        "\n",
        "2) OPENAPI_API_KEY - (you can find it here https://platform.openai.com/settings/profile?tab=api-keys).\n",
        "\n",
        "3) PERPLEXITY_API_KEY - You can generate an API key here: https://docs.perplexity.ai/docs/getting-started\n",
        "\n",
        "These secrets can be set in your Google colab account using the key on the left side.\n",
        "\n",
        "*See the [Github repo](https://github.com/ryooan/metaculus-bot-forecaster) for special instructions necessary for setting your secrets in Github if you intend to use the automated Github action.*\n",
        "\n",
        "*Note: previously this also used a QUESTIONS_API_KEY which got some precomputed Perplexity results stored by Metaculus, but this is no longer supported by Metaculus.*\n",
        "\n",
        "### Setting Inputs\n",
        "\n",
        "Once your tokens are set correctly, you can proceed to the [Inputs section](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=6cbruBaVtaZh). That should be the only section most users will need. More advanced users can edit the [Setup](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=tNl_mbJaX60R) and [Code](https://colab.research.google.com/drive/1_P7_QNJiJyWBY2qCVu2-_8gVPD1X7mX3?authuser=2#scrollTo=k8vtze4SXtR3) sections if desired, but this is not recommended unless you have coding experience."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "It is recommended that you do not edit these cells unless you have coding experience.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tNl_mbJaX60R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css(*args, **kwargs):\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "#according to this link the above wraps the output text: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results"
      ],
      "metadata": {
        "id": "girVrSlJkWUL",
        "outputId": "b6c87180-4c84-4cbe-8248-fb2930f9f02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "HifodCwcGU0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8a4c2deb-1a34-499a-e153-91ece2869da6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import tiktoken\n",
        "import re\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "#use the below to detect if it's being run in google colab, if it's not this skips an error\n",
        "def in_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "SoELZnYOGXsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e51c73a6-55f8-468d-a381-e8f854909e7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading secrets from userdata (Google Colab)\n"
          ]
        }
      ],
      "source": [
        "#the below is used to get secrets when using github actions to automate\n",
        "#initialize\n",
        "token = None\n",
        "#questions_api_key = None\n",
        "perplexity_api_key = None\n",
        "\n",
        "# Function to load secrets from the specified path\n",
        "def load_secrets(secrets_path):\n",
        "    try:\n",
        "        with open(secrets_path, 'r') as secrets_file:\n",
        "            secrets = json.loads(secrets_file.read())\n",
        "            for k, v in secrets.items():\n",
        "                os.environ[k] = v\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading secrets from {secrets_path}: {e}\")\n",
        "\n",
        "# Main code block\n",
        "try:\n",
        "    if 'secretsPath' in globals():\n",
        "        print(f\"secretsPath exists: {secretsPath}\")\n",
        "        load_secrets(secretsPath)\n",
        "\n",
        "        token = os.environ['METACULUS_TOKEN']\n",
        "        #questions_api_key = os.environ['QUESTIONS_API_KEY']\n",
        "        perplexity_api_key = os.environ['PERPLEXITY_API_KEY']\n",
        "    else:\n",
        "        raise NameError(\"secretsPath not defined\")\n",
        "except NameError:\n",
        "    print(\"Loading secrets from userdata (Google Colab)\")\n",
        "    token = userdata.get('METACULUS_TOKEN')\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    #questions_api_key = userdata.get('QUESTIONS_API_KEY')\n",
        "    perplexity_api_key = userdata.get('PERPLEXITY_API_KEY')\n",
        "except KeyError as e:\n",
        "    print(f\"Missing required environment variable: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs\n",
        "\n",
        "The cell below contains all of the main settings that you can change. See comments in the cell for an explanation of each. Modify them as you see fit and then run all of the cells below to forecast.\n",
        "\n",
        "*You can press Ctrl+F10 to run all of the cells after the selected one.*"
      ],
      "metadata": {
        "id": "6cbruBaVtaZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 3349  # 3129 is ID of AI Becnhmarking Pilot project. We kindly ask you not to forecast on any public tournaments or public questions in general\n",
        "MAX_QUESTIONS_TO_FORECAST = 25  # You can set it to some small number for testing or to 1_000_000 to forecast on all available questions\n",
        "REPREDICT = False # if this is false it won't predict on questions it has previously already predicted on. Set it to true to repredict on all open questions, even if it has made previous predictions.\n",
        "SUBMIT_FORECASTS = True # If set to False - forecast, but don't submit results to Metaculus platform. If set to True - forecast, and submit results to Metaculus platform\n",
        "USE_PERPLEXITY_RECENT = True # If set to true the perplexity search used is one that looks for the most recent news on the subject using a GPT prompt completion informed by the forecasting question.\n",
        "QUESTION_IDS_TO_FORECAST = None # Set to None to disable custom filtering by ID. Set to a list of IDs to only forecast on selected questions, i.e. [24191, 24190, 24189]\n",
        "#QUESTION_IDS_TO_FORECAST = [26233, 26234]\n",
        "\n",
        "# Use this to run your own question, not pulled from Metaculus\n",
        "ANSWER_MANUAL_QUESTION = False\n",
        "manual_question = \"Will Pfizer's GLP-1 trial agent danuglipron be approved by the FDA for weight loss by January 1 2028?\"\n",
        "manual_question_dict = {\n",
        "  'id': None,\n",
        "  'title': manual_question,\n",
        "  'description': manual_question,\n",
        "  'resolution_criteria': manual_question,\n",
        "  'fine_print': manual_question\n",
        "  }\n",
        "if ANSWER_MANUAL_QUESTION:\n",
        "  SUBMIT_FORECASTS = False\n",
        "\n",
        "OPEN_AI_MODEL = 'gpt-4'\n",
        "PERPLEXITY_MODEL = 'llama-3-sonar-large-32k-online'\n",
        "\n",
        "# The forecaster weights are used to produce a weighted average of the forecasts. You can adjust these weights to favor a certain forecaster/prompt more heavily.\n",
        "# Weights should sum to 1.\n",
        "forecaster1_weight = 0.2\n",
        "forecaster2_weight = 0.2\n",
        "forecaster3_weight = 0.2\n",
        "forecaster4_weight = 0.4\n",
        "\n",
        "# Prompts\n",
        "# The prompts used are below, these can be edited to hone your LLM forecasts.\n",
        "# Here is a glossary of the variables that can be inserted and used in the prompts.\n",
        "# [[title]]: This is the question text, what shows up at the top of the Metaculus question page\n",
        "# [[resolution_criteria]]: This is the resolution criteria section of the question, excluding fine print\n",
        "# [[fine_print]]: This is the fine print section of the question.\n",
        "# [[background]]: This is the background section of the resolution criteria.\n",
        "# [[today]]: The current date\n",
        "# [[forecaster1]] through {forecaster3}: These are the LLM outputs of forecasters 1 through 3, currently being used to feed into the input of forecaster 4 for it to assess in its own forecast.\n",
        "# [[summary_report]]: This is research from Perplexity. If USE_PERPLEXITY_RECENT is True, this will be the Perplexity info returned when the output of LLM_question_completion is passed to Perplexity.\n",
        "                  # If USE_PERPLEXITY_RECENT is False and ENABLE_PERPLEXITY_RESEARCH is True, it will return pre-computed Perplexity research on the question stored by Metaculus.\n",
        "                  # If both are false it will not return anything.\n",
        "\n",
        "# The LLM_question_completion prompt is used to ask the LLM what question it should ask Perplexity, if using USE_PERPLEXITY_RECENT\n",
        "prompt_template_get_perplexity_question = \"\"\"\n",
        "You're being asked the following forecasting question:\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "And it has these specific resolution details:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Fine print:\n",
        "[[fine_print]]\n",
        "\n",
        "To get the latest news that will help you forecast on the question, you need to ask your web search tool one question that would be most valuable to help you forecast\n",
        "on this question. The question should be posed so that the web search tool will provide you with the most recent information, including the latest information on the progress toward\n",
        "the criteria in the forecasting question being met. Please complete the sentence below with the most valuable question to ask:\n",
        "\n",
        "\"What is the most recent news available and prior occurrences related to. . . \"\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 1 is used by forecaster 1, with PROMPT_TEMPLATE appended to the end\n",
        "prompt_template_v1 = \"\"\"\n",
        "You are a professional forecaster interviewing for a job. The interviewer is also a professional forecaster, with a strong track record of accurate forecasts of the future.\n",
        "They will ask you a question, and your task is to provide the most accurate forecast you can. To do this, you evaluate past data and trends carefully, make use of comparison classes\n",
        "of similar events, take into account base rates about how past events unfolded, and outline the best reasons for and against any particular outcome.\n",
        "You know that great forecasters don't just forecast according to the \"vibe\" of the question and the considerations.\n",
        "Instead, they think about the question in a structured way, recording their reasoning as they go,\n",
        "and they always consider multiple perspectives that usually give different conclusions, which they reason about together.\n",
        "You can't know the future, and the interviewer knows that, so you do not need to hedge your uncertainty, you are simply trying to give\n",
        "the most accurate numbers that will be evaluated when the events later unfold.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 2 is used by forecaster 2, with PROMPT_TEMPLATE appended to the end\n",
        "prompt_template_v2 = \"\"\"\n",
        "You are a professional forecaster being tested on your skill. You are being asked a question for which you must provide the most accurate forecast you can.\n",
        "Reason step by step about the best forecast, carefully considering the information you are presented with and the potential that some of the\n",
        "background information and information provided by your research assistant may be out of date or conflicting.\n",
        "You also know that a key forecasting practice is to consider the outside view, thinking carefully about reference classes and base rates and how often similar events\n",
        "have happened in the past.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 3 is used by forecaster 3, with PROMPT_TEMPLATE appended to the end\n",
        "prompt_template_v3 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below. You have a keen eye for detail, and know that\n",
        "the resolution criteria and fine print of a question often contain important edge cases that should be considered. You also know that rookie forecasters\n",
        "tend to be underconfident, and so your forecasts should be confident and extremize some of the way toward 1% or 99%. You're also aware that forecasting questions tend\n",
        "to be biased, so when forecasting questions asks about things that would be a departure from the norm or from business as usual, those things tend not to happen.\n",
        "You will use that knowledge to make the best forecast you can, and describe your reasoning step by step.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Forecaster 4 uses prompt 4 parts 1 and 2, with PROMPT_TEMPLATE inserted between part 1 and part 2\n",
        "final_prompt_part1 = \"\"\"\n",
        "You are a professional forecaster trying your best to produce an accurate forecast for the question below.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "final_prompt_part2 = \"\"\"\n",
        "Now that you know what the question asks and some relevant background and research, your job is to make the best forecast you can. You know that examining the reasoning of other\n",
        "forecasters is an excellent way to improve your own forecast. Below I have provided the reasoning from three other forecasters who predicted on the same question.\n",
        "Examine their reasoning and use it to inform your own, using your expertise as a forecaster to assess which reasoning seems strongest and which seems flawed,\n",
        "as well as which reasoning seems to incorporate the most accurate information about base rates and historic reference classes. Construct your own reasoning and forecast,\n",
        "describing your reasoning step by step and incorporating the strongest arguments from the other forecasters in a way that improves your own reasoning. First produce a\n",
        "one sentence summary of the reasoning of each forecaster (repeating the final probability each predicted), then describe your forecast.\n",
        "\n",
        "Forecaster A:\n",
        "[[forecaster1]]\n",
        "\n",
        "Forecaster B:\n",
        "[[forecaster2]]\n",
        "\n",
        "Forecaster C:\n",
        "[[forecaster3]]\n",
        "\"\"\"\n",
        "\n",
        "# PROMPT_TEMPLATE is used with the above prompts to share the details about the question with the LLM.\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "\n",
        "The question is:\n",
        "[[title]]\n",
        "\n",
        "Here are details about how the outcome of the question will be determined, make sure your forecast is consistent with these:\n",
        "[[resolution_criteria]]\n",
        "\n",
        "Here is the question's fine print that you need to be consistent with in your forecast:\n",
        "[[fine_print]]\n",
        "\n",
        "Here is some background of the question, though note that some of the details may be out of date:\n",
        "[[background]]\n",
        "\n",
        "Your research assistant provides the following information that is likely more up to date:\n",
        "[[summary_report]]\n",
        "\n",
        "Today is [[today]].\n",
        "\n",
        "Describe your reasoning step by step and give your final answer as: \"Probability: ZZ%\", 0-100\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2CWVjJ9_tZ6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "11db1d3b-0230-41bc-dfdd-0b093a6dd2da"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "It is recommended that you do not edit the below unless you have coding experience.\n",
        "\n",
        "Note that currently the LLM is set to gpt-4o, and this is specified in the code below. This can be changed by advanced users, though changing between OpenAI models is much simpler than changing to a model from a different AI organizations.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k8vtze4SXtR3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmWSCwDLbhFJ"
      },
      "source": [
        "Getting questions (only binaries)\n",
        "\n",
        "Getting them 10 at a time, you can change offset to \"scroll\" through them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "O9gVXbHIGfOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3384233e-902f-4b3e-fb59-89d39b62f3a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "url = \"https://www.metaculus.com/api2/questions/\"\n",
        "\n",
        "params = {\n",
        "    \"has_group\": \"false\",\n",
        "    \"order_by\": \"-activity\",\n",
        "    \"forecast_type\": \"binary\",\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"status\": \"open\", # can change this to 'closed' for testing where you're not submitting a forecast, otherwise leave as open\n",
        "    \"type\": \"forecast\",\n",
        "    \"title-and-description-only\": \"true\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "yioIDa8UsCuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "610c7ec7-821b-4bab-c4b9-8b604f8940b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def yield_all_questions():\n",
        "  if ANSWER_MANUAL_QUESTION:\n",
        "    yield manual_question_dict\n",
        "    return\n",
        "\n",
        "  limit = 10 # This is a page limit, not question limit\n",
        "  n = 0\n",
        "  new_questions_found = False\n",
        "\n",
        "  while True:\n",
        "    offset = n * limit\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        params={**params, \"limit\": limit, \"offset\": offset},\n",
        "        headers={\"Authorization\": f\"Token {token}\"}\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "    questions = response.json().get(\"results\")\n",
        "\n",
        "    # if repredict is true it will skip to the else and predict on all the questions\n",
        "    # if repredict is false it will see if \"my_predictions\" is empty or not for each question, and only predict on questions without a prediction\n",
        "    if not REPREDICT:\n",
        "        for question in questions:\n",
        "            question_id = question['id']\n",
        "\n",
        "            guess_response = requests.get(\n",
        "                f\"{url}{question_id}/\",\n",
        "                headers={\"Authorization\": f\"Token {token}\"}\n",
        "            )\n",
        "            guess_response.raise_for_status()\n",
        "\n",
        "            if not guess_response.json().get(\"my_predictions\"):\n",
        "                new_questions_found = True\n",
        "                yield question\n",
        "    else:\n",
        "        new_questions_found = True\n",
        "        yield from questions\n",
        "\n",
        "    if not response.json().get(\"next\"):\n",
        "      break\n",
        "    n += 1\n",
        "\n",
        "  if not new_questions_found:\n",
        "        print(\"No new questions to predict on.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "dXyQLerREJGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cfa5a3e4-3af1-4eb1-e3cc-fac24ce636bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def find_number_before_percent(s):\n",
        "    # Use a regular expression to find all numbers followed by a '%'\n",
        "    matches = re.findall(r'Probability[:\\s]+(\\d+)%', s)\n",
        "    if matches:\n",
        "        # Return the last number found before a '%'\n",
        "        return int(matches[-1])\n",
        "    else:\n",
        "        # Return None if no number found\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is used to replace the {} keys with [[]], since sometimes the LLM output uses {} when formatting code.\n",
        "def replace_keys(text, key_dict, delimiter='[[', end_delimiter=']]'):\n",
        "    pattern = re.compile(re.escape(delimiter) + '(.*?)' + re.escape(end_delimiter))\n",
        "    def replace(match):\n",
        "        key = match.group(1)\n",
        "        return key_dict.get(key, match.group(0))  # Return the original if key not found\n",
        "    return pattern.sub(replace, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ldAJ5OWBW1mA",
        "outputId": "dc2b89c8-880f-41e1-d107-fd2e122f70be"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "EoV2KKC8l5im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "512e8a6f-c72a-443f-d0d6-efc8d1466494"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def predict(question_id, prediction_percentage):\n",
        "  url = f\"https://www.metaculus.com/api2/questions/{question_id}/predict/\"\n",
        "  response = requests.post(\n",
        "      url,\n",
        "      json={\n",
        "        \"prediction\": float(prediction_percentage) / 100\n",
        "      },\n",
        "      headers={\"Authorization\": f\"Token {token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(f\"Successfully predicted {prediction_percentage} on question {question_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "AJUGVfHVrms2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "576bd41c-f793-49c3-b421-2c0a905bfe0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def formulate_comment(prediction_json):\n",
        "  comment_blocks = []\n",
        "  if \"reasoning_base_rate\" in prediction_json:\n",
        "    comment_blocks.append(\"## Base rate estimation\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_base_rate\"])\n",
        "  if \"reasoning_reference_classes\" in prediction_json:\n",
        "    comment_blocks.append(\"## Reference classes\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_reference_classes\"])\n",
        "  if \"reasoning_other\" in prediction_json:\n",
        "    comment_blocks.append(\"## Additional\")\n",
        "    comment_blocks.append(prediction_json[\"reasoning_other\"])\n",
        "  return \"\\n\".join(comment_blocks) if comment_blocks else \"No reasoning provided\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "7uhKwbzQsKby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4cd55642-8bd1-4a7a-8450-956399960b81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def comment(question_id, comment_text):\n",
        "\n",
        "  # for submit_type choose \"S\" to post regular comment and \"N\" for private. Tournament submissions should be private comments.\n",
        "  url = f\"https://www.metaculus.com/api2/comments/\"\n",
        "  response = requests.post(\n",
        "    url,\n",
        "    json={\n",
        "      \"comment_text\":comment_text,\"submit_type\":\"N\",\"include_latest_prediction\":True,\"question\":question_id\n",
        "    },\n",
        "    headers={\"Authorization\": f\"Token {token}\"},\n",
        "  )\n",
        "  response.raise_for_status()\n",
        "  print(\"Comment Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "T2PaTg5H6muR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f91017c9-eb08-412c-ac8d-0993a345f6e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#def get_perplexity_research(question_id):\n",
        "#  url = \"https://ml.metaculus.com/questions-api/perplexity-research-results/\"\n",
        "#  headers = {\n",
        "#    \"accept\": \"application/json\",\n",
        "#    \"X-API-Key\": questions_api_key,\n",
        "#    \"content-type\": \"application/json\"\n",
        "#  }\n",
        "#  params = {\n",
        "#    \"question_id\": question_id\n",
        "#  }\n",
        "#  response = requests.get(url=url, params=params, headers=headers)\n",
        "#  if response.status_code == 404:\n",
        "#    print(\"No Perplexity research found\")\n",
        "#    return \"No results found, please use your own knowledge and judgement to forecast\"\n",
        "#  content = response.text\n",
        "\n",
        "#  print(\"Generated research from perplexity:\")\n",
        "#  print(content)\n",
        "#  return content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_pricing(input, output, model):\n",
        "  encoding = tiktoken.encoding_for_model(model)\n",
        "  input_len = len(encoding.encode(input))\n",
        "  output_len = len(encoding.encode(output))\n",
        "\n",
        "\n",
        "  # hard coding for now, maybe make it smarter later\n",
        "  # units of $ per token\n",
        "  gpt4o_input_pricing = 5 / 1_000_000\n",
        "  gpt4o_output_pricing = 15 / 1_000_000\n",
        "\n",
        "  input_cost = input_len * gpt4o_input_pricing\n",
        "  output_cost = output_len * gpt4o_output_pricing\n",
        "  total_cost = input_cost + output_cost\n",
        "\n",
        "  return input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "THGjV1tPd_7Q",
        "outputId": "fa2d399c-6146-47dd-d706-9b51e66d65c1"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm(today, client, template_values, prompt_template, summary_report, model, looking_for_probability=True):\n",
        "\n",
        "  title = template_values[\"title\"]\n",
        "  resolution_criteria = template_values[\"resolution_criteria\"]\n",
        "  background = template_values[\"description\"]\n",
        "  if template_values[\"fine_print\"]:\n",
        "    fine_print = template_values[\"fine_print\"]\n",
        "  else:\n",
        "    fine_print = \"none\"\n",
        "\n",
        "  prompt_dict = {\n",
        "      \"title\": title,\n",
        "      \"summary_report\": summary_report,\n",
        "      \"today\": today,\n",
        "      \"background\": background,\n",
        "      \"fine_print\": fine_print,\n",
        "      \"resolution_criteria\": resolution_criteria,\n",
        "  }\n",
        "\n",
        "  prompt_text = replace_keys(prompt_template, prompt_dict)\n",
        "\n",
        "  #print(\"Here is the prompt used:\")\n",
        "  #print(\"prompt_text\")\n",
        "  #print(prompt_text)\n",
        "  #print(\"\")\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt_text\n",
        "      }\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  gpt_text = chat_completion.choices[0].message.content\n",
        "\n",
        "  #estimate cost\n",
        "  input_cost, output_cost, total_cost = estimate_pricing(prompt_text, gpt_text, model)\n",
        "\n",
        "  if looking_for_probability:\n",
        "    # Regular expression to find the number following 'Probability: '\n",
        "    probability_match = find_number_before_percent(gpt_text)\n",
        "\n",
        "    # Extract the number if a match is found\n",
        "    if probability_match:\n",
        "        probability = int(probability_match) # int(match.group(1))\n",
        "        #print(f\"The extracted probability is: {probability}%\")\n",
        "        #probability = min(max(probability, 3), 97) # To prevent extreme forecasts\n",
        "    else:\n",
        "        probability = None\n",
        "        print(\"No probability found in the text! Skipping!\")\n",
        "  else:\n",
        "    probability = None\n",
        "  return probability, gpt_text, input_cost, output_cost, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XK4FbnKJb98Q",
        "outputId": "a6b24133-5c38-4797-e190-287c88e7555b"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_perplexity(perplexity_prompt, perplexity_api_key):\n",
        "\n",
        "  from openai import OpenAI\n",
        "\n",
        "  YOUR_API_KEY = perplexity_api_key\n",
        "\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": (\n",
        "              \"You are an artificial intelligence assistant and you need to \"\n",
        "              \"engage in a helpful, detailed, polite conversation with a user.\"\n",
        "          ),\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": (\n",
        "              perplexity_prompt\n",
        "          ),\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  perplexity_client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
        "\n",
        "  # chat completion without streaming\n",
        "  response = perplexity_client.chat.completions.create(\n",
        "      model=PERPLEXITY_MODEL,\n",
        "      messages=messages,\n",
        "  )\n",
        "\n",
        "  content = response.choices[0].message.content\n",
        "\n",
        "  print(\"Generated research from perplexity:\")\n",
        "  print(content)\n",
        "  print(\"\")\n",
        "\n",
        "  # get token and cost estimate\n",
        "\n",
        "  # currently using the GPT tokenizer with a 1.3 multiplier. Hacky and wrong, but rough estimate.\n",
        "  # See here for 1.3 factor estimate source: https://github.com/continuedev/continue/issues/878\n",
        "\n",
        "  perplexity_token_pricing = 1/1_000_000\n",
        "  perplexity_cost_fixed = 5/1_000\n",
        "\n",
        "  multiplier = 1.3\n",
        "  encoding = tiktoken.encoding_for_model(OPEN_AI_MODEL)\n",
        "  input_text = perplexity_prompt\n",
        "  output_text = content\n",
        "  input_len = len(encoding.encode(input_text)) * multiplier\n",
        "  output_len = len(encoding.encode(output_text)) * multiplier\n",
        "\n",
        "  input_cost = input_len * perplexity_token_pricing\n",
        "  output_cost = output_len * perplexity_token_pricing\n",
        "  fixed_cost = perplexity_cost_fixed\n",
        "  total_cost = input_cost + output_cost + perplexity_cost_fixed\n",
        "\n",
        "  print(f\"Total perplexity call cost: ${total_cost}\")\n",
        "  print(\"\")\n",
        "\n",
        "  return content, total_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gWXOgDDWx7il",
        "outputId": "8cf4e64e-3082-421f-a67e-7767b17d2a5d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "W-wVKhWomV2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e6c68ec8-54c3-4fe9-d4c5-4dddc70b52a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def clean_gpt_turbo_markdown(text: str) -> str:\n",
        "  match = re.search(r\"```[\\w]+\\s+(.*?)\\s+```\", text, re.DOTALL)\n",
        "  if match:\n",
        "    cleaned_text = match.group(1).strip()\n",
        "  else:\n",
        "    cleaned_text = text\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwc6I64ScFUz"
      },
      "source": [
        "Forecast on all questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "3C52dUgSG6Pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70043e52-5244-48cc-9348-544e29714b99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Forecasting Question:\n",
            "26234 Will an avian influenza virus in humans be declared a â€œPublic Health Emergency of International Concernâ€ by the World Health Organization before Sept 30, 2024?\n",
            "\n",
            "Getting Perplexity recent data...\n",
            "\n",
            "The completed question posed to perplexity reads: What is the most recent news available and prior occurrences related to \"Avian influenza virus outbreaks in humans and WHO's declaration of Public Health Emergencies of International Concern?\"\n",
            "Generated research from perplexity:\n",
            "The most recent news available regarding avian influenza virus outbreaks in humans and the World Health Organization's (WHO) declaration of Public Health Emergencies of International Concern (PHEIC) is as follows:\n",
            "\n",
            "### Recent Cases and Outbreaks\n",
            "\n",
            "- **United States**: As of July 12, 2024, the Centers for Disease Control and Prevention (CDC) reported four human cases of avian influenza A(H5N1) virus infection associated with a multistate outbreak in dairy cows. The cases were reported in Texas, Michigan, and Colorado.\n",
            "- **Mexico**: On June 5, 2024, the WHO reported a human case of avian influenza A(H5N2) virus infection. The source of exposure is currently unknown, but high pathogenicity avian influenza A(H5N2) outbreaks were detected in poultry in the states of MichoacÃ¡n and Texcoco, and low pathogenicity avian influenza (LPAI) A(H5N2) was identified in poultry in Texcoco and Temascalapa.\n",
            "- **Western Pacific Region**: As of January 31, 2024, the WHO reported various cases of human infection with different avian influenza subtypes in the Western Pacific Region. These include A(H5N1), A(H5N6), A(H3N8), A(H7N4), A(H7N9), and A(H9N2).\n",
            "\n",
            "### Prior Occurrences\n",
            "\n",
            "- **United States**: In January 2022, the USDA reported an HPAI A(H5N1) virus outbreak in commercial poultry. Additionally, the first H5N1 detection in wild birds in the US since 2016 was reported on January 14, 2024.\n",
            "- **Global**: From 2003 to April 1, 2024, a total of 889 cases and 463 deaths (case fatality ratio of 52%) caused by influenza A(H5N1) virus have been reported worldwide from 23 countries.\n",
            "\n",
            "### WHO Response and Guidance\n",
            "\n",
            "- The WHO continues to monitor the situation and provides technical guidance for the detection of zoonotic influenza using molecular methods. The organization also updates guidelines on influenza surveillance and response at the human-animal interface.\n",
            "- The WHO assesses the public health risk to the general population posed by these viruses to be low, but for occupationally exposed persons, the risk of infection is considered low-to-moderate.\n",
            "\n",
            "### Public Health Measures\n",
            "\n",
            "- Local and national health authorities have implemented various public health measures, including epidemiological investigations, contact tracing, and surveillance of influenza-like illnesses and severe acute respiratory illnesses.\n",
            "- The CDC is working in collaboration with the USDA, FDA, state public health and animal health officials, and other partners using a One Health approach to respond to the multistate outbreak of avian influenza A(H5N1) virus in dairy cows and other animals in the United States.\n",
            "\n",
            "These recent cases and outbreaks highlight the ongoing concern about avian influenza viruses and their potential to infect humans, emphasizing the need for continued surveillance and public health measures to mitigate the risk of transmission.\n",
            "\n",
            "Total perplexity call cost: $0.0058697\n",
            "\n",
            "Running initial prompt 1\n",
            "Output Reasoning:\n",
            "Step 1: Understanding Past Data and Trends\n",
            "\n",
            "The occurrence of avian influenza and its zoonotic transmission to humans has been consistent over the past decades. Numerous outbreaks have been reported globally, with the most severe being the H5N1 strain that resulted in a case fatality of 52%. \n",
            "\n",
            "Nonetheless, none of these outbreaks has been categorized as a Public Health Emergency of International Concern (PHEIC) by the World Health Organization. This demonstrates exceptional scrutiny in declaring a PHEIC by the international organization, with only major and extensive outbreaks such as H1N1 and COVID-19 making the cut. \n",
            "\n",
            "Step 2: Identifying Influential Factors\n",
            "\n",
            "Several factors come into question. These include the pathogenicity of the virus in humans, human-to-human transmissibility, public health measures, evolution of the virus, and the global impact of the avian influenza outbreaks.\n",
            "\n",
            "Key factors seem to be:\n",
            "\n",
            "1. **Human-to-human transmissibility**: Currently, avian influenza primarily spreads from birds to humans, and human-to-human transmission is unusual. Sustained human-to-human transmission would increase the likelihood of widespread outbreaks and its categorization as a PHEIC.\n",
            "  \n",
            "2. **Public Health Measures**: Effective surveillance, prompt case detection, and containment could hinder widespread outbreaks and reduce the likelihood of a PHEIC declaration.\n",
            "\n",
            "3. **Virus Evolution**: Mutations leading to increased transmissibility or severity of the disease in humans could increase the likelihood of a PHEIC declaration.\n",
            "\n",
            "Step 3: Assess the Current Situation \n",
            "\n",
            "As of July 12, 2024, there have been several outbreaks reported in different countries. However, these have been relatively contained and the public health risk remains low according to the WHO. \n",
            "\n",
            "Step 4: Weigh the Influential Factors\n",
            "\n",
            "Given that evidence currently suggests the risk remains low and no instances of sustained human-to-human transmission or increased severity have been reported, it seems less likely a PHEIC would be declared in the near future. \n",
            "\n",
            "However, the global distribution of outbreaks and the recent jump to abundant mammalsâ€”the dairy cattleâ€”opens up possibilities for virus evolution and larger outbreaks.\n",
            "\n",
            "Step 5: Final Evaluation and Forecast\n",
            "\n",
            "Taking into consideration all the aforementioned reasoning, I believe there exists a moderate chance of an avian influenza outbreak being categorized as a PHEIC by the WHO before September 30, 2024. \n",
            "\n",
            "Final Probability: 35%\n",
            "\n",
            "Extracted probability percentage value (0-100): 35\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 2\n",
            "Output Reasoning:\n",
            "This is a complex forecasting question that requires a balance of multiple pieces of information, including historical trends, current occurrence rates, expert opinions and evolving circumstances.\n",
            "\n",
            "Historically, the World Health Organization has declared a \"Public Health Emergency of International Concern\" (PHEIC) very rarely. Two examples of such declarations are the H1N1 pandemic in 2009 and the COVID-19 pandemic in 2020. While there is currently an uptick in cases of avian influenza A(H5N1) in humans, this is still quite rare.\n",
            "\n",
            "The WHO continues to monitor the situation, but currently assesses the public health risk to the general population posed by these viruses as low. For occupationally exposed persons, the risk of infection is considered low-to-moderate. While this assessment could change if circumstances change dramatically, the time frame of our prediction (before Sept 30, 2024) is relatively short and it takes time for an epidemic situation to escalate to a point of international concern.\n",
            "\n",
            "The background information also explains that an outbreak of a virus classified as a â€œHighly Pathogenic Avian Influenzaâ€ presenting in humans must be declared a PHEIC by the World Health Organization to satisfy the conditions of this question. Currently, we have instances of infection but not an outbreak in the technical sense. Also significant to note is that there has not been sustained human-to-human transmission noted, which would typically be a key factor in escalating this to a PHEIC.\n",
            "\n",
            "However, the recent jump of Highly Pathogenic Avian Influenza (HPAI), Type A, subtype H5N1 to dairy cattle does introduce new variables that could potentially escalate the situation. The multiple cases in the US and the range of mixed situations across nations, present potential risks. This is particularly so if there are further developments that increase human-to-human transmission.\n",
            "\n",
            "Given all the factors at play here, it seems there is a potential but relatively low likelihood that the WHO will declare a PHEIC for an avian influenza virus in humans before Sept 30, 2024. Considering all the information available and after balancing the historical base rate of PHEIC declarations, I would estimate: \"Probability: 15%\".\n",
            "\n",
            "Extracted probability percentage value (0-100): 15\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "Running initial prompt 3\n",
            "Output Reasoning:\n",
            "Based on the provided information, let's break down the factors we need to consider.\n",
            "\n",
            "Some reasons to be concerned:\n",
            "- There's already been detected case of H5N1, one of the highly pathogenic avian influenza (HPAI) viruses, in humans. Human infections with HPAI viruses have historical precedent to be considered as public health emergencies by the WHO, like H1N1 in 2009 and COVID-19 in 2020.\n",
            "- There's a confirmed breakout of H5N1 in cows in the US and both H5N1 and H5N2 have been detected in birds in different regions. \n",
            "- There are multiple regions are facing outbreaks of different kinds of avian influenza viruses, increasing the overall likelihood.\n",
            "\n",
            "Neutral or factors that we're uncertain about:\n",
            "- The cases of H5N1 in humans so far are just four incidences. Not much data on how quickly it's spreading, if at all.\n",
            "- Human infection through exposure to infected livestock or birds isn't a guarantee that the virus can transmit from human to human.\n",
            "- The case in Mexico seems isolated and it's unclear if the virus is spreading there at all.\n",
            "- Details on the Western Pacific region case are sparse. \n",
            "\n",
            "Some reasons not to be concerned:\n",
            "- The flu season in the Northern hemisphere is tapering off (it's July currently), and that might decrease the opportunities for the virus to spread.\n",
            "- The WHO currently only sees a low-to-moderate risk for people who are occupationally exposed, and a low risk for the general public.\n",
            "- Human-to-human transmission is required for a higher chance of a pandemic, and it's not yet clear if the H5N1 or H7N9 are capable of this.\n",
            "- Between 2003 - 2024, H5N1 has only infected 889 people worldwide, a relatively low figure over a span of over 20 years.\n",
            "\n",
            "On balance, while there's clear potential for concern and should be closely monitored, right now the evidence points towards a lower chance of the WHO declaring avian influenza in humans a PHEIC. \n",
            "\n",
            "Using all the above information, I would put the probability at around 10%. \n",
            "\n",
            "Final Answer: Probability: 10%, 0-100\n",
            "\n",
            "\n",
            "Extracted probability percentage value (0-100): 10\n",
            "\n",
            "~~~~ NEXT PROMPT ~~~~\n",
            "\n",
            "+++++++++++ FINAL PROMPT (4) +++++++++++++++++\n",
            "Running final prompt...\n",
            "\n",
            "Summary of Forecaster A's reasoning: Considering past cases, current health measures along with possibilities for the virus evolution and human-to-human transmission, the forecaster concludes with a 35% probability for an avian influenza outbreak to be declared a PHEIC by the WHO before September 30, 2024.\n",
            "\n",
            "Summary of Forecaster B's reasoning: Taking into account the rarity of PHEIC, current low risk assessment by the WHO, lack of sustained human-to-human transmission, and the recent jump of H5N1 to cattle, the forecaster gives a 15% chance of an outbreak being declared a PHEIC by the WHO in the given timeframe.\n",
            "\n",
            "Summary of Forecaster C's reasoning: Based on some factors raising concern, some neutral or uncertain factors, and reasons not to be concerned, the forecaster sees a lower chance of the WHO declaring an avian influenza outbreak in humans a PHEIC with a 10% probability.\n",
            "\n",
            "My Forecast:\n",
            "The three forecasters bring up key aspects to be considered for this prediction.  \n",
            "- Historic precedent: While avian influenza has seen numerous outbreaks, none yet has been declared a PHEIC by the WHO.\n",
            "- Outbreak occurrence and severity: Several cases have been detected in humans already in different regions.\n",
            "- Virus transmission and evolution: Sustained human-to-human transmission hasn't been observed yet, but the virus jumping to mammals indicates potential for further evolution.\n",
            "- WHO's risk assessment: WHO currently assesses low risk to the general populace and moderate for those with occupational exposure.\n",
            "- Short-term forecast horizon: The time frame of our forecast is relatively short, giving less time for a situation to develop into a PHEIC.\n",
            "\n",
            "Balancing these factors, I agree with Forecaster C that although there are reasons for concern, the evidence currently leans toward a lower chance of a PHEIC declaration for avian influenza in humans within this timeframe. Temporary upsurges in cases have happened without escalating to a PHEIC status. The fact that no sustained human-to-human transmission has been reported so far is highly relevant, as this is crucial for a pandemic level spread.\n",
            "\n",
            "However, the new evidence of the virus now affecting cattle - a livestock which has more frequent human contact - cannot be ignored. This represents a new variable and potentially increases the risk. Utilizing the base rate of previous PHEIC declarations and noting that even major outbreaks like H5N1 have not been classified as such, this currently seems less likely unless significant changes like a virus mutation or a sudden surge in human-to-human transmission occur. \n",
            "\n",
            "Taking these factors and the other forecasters' predictions into account, I would adjust the forecast slightly from Forecaster C and put the probability at around 12%.\n",
            "\n",
            "Final Answer: Probability: 12%, 0-100.\n",
            "\n",
            "Final prompt's individual (non-weighted) extracted probability percentage value (0-100): 12\n",
            "\n",
            "Rationale to submit:\n",
            "\n",
            "\n",
            "  *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
            "\n",
            "  * *Main LLM Model used: gpt-4*\n",
            "  * *Weighted formula: (0.2)(Forecaster A) + (0.2)(Forecaster B) + (0.2)(Forecaster C) + (0.4)(Summary Forecaster)*\n",
            "  * *Estimated cost of model calls based on tokens (may be incorrect due to differing token costs based on model used): $0.071*\n",
            "  * *** FINAL WEIGHTED FORECAST: 16.8%***\n",
            "\n",
            "  ---\n",
            "\n",
            "  \n",
            "\n",
            "Successfully predicted 16.8 on question 26234\n",
            "Comment Success!\n",
            "Output Reasoning:\n",
            "Summary of Forecaster A's reasoning: Considering past cases, current health measures along with possibilities for the virus evolution and human-to-human transmission, the forecaster concludes with a 35% probability for an avian influenza outbreak to be declared a PHEIC by the WHO before September 30, 2024.\n",
            "\n",
            "Summary of Forecaster B's reasoning: Taking into account the rarity of PHEIC, current low risk assessment by the WHO, lack of sustained human-to-human transmission, and the recent jump of H5N1 to cattle, the forecaster gives a 15% chance of an outbreak being declared a PHEIC by the WHO in the given timeframe.\n",
            "\n",
            "Summary of Forecaster C's reasoning: Based on some factors raising concern, some neutral or uncertain factors, and reasons not to be concerned, the forecaster sees a lower chance of the WHO declaring an avian influenza outbreak in humans a PHEIC with a 10% probability.\n",
            "\n",
            "My Forecast:\n",
            "The three forecasters bring up key aspects to be considered for this prediction.  \n",
            "- Historic precedent: While avian influenza has seen numerous outbreaks, none yet has been declared a PHEIC by the WHO.\n",
            "- Outbreak occurrence and severity: Several cases have been detected in humans already in different regions.\n",
            "- Virus transmission and evolution: Sustained human-to-human transmission hasn't been observed yet, but the virus jumping to mammals indicates potential for further evolution.\n",
            "- WHO's risk assessment: WHO currently assesses low risk to the general populace and moderate for those with occupational exposure.\n",
            "- Short-term forecast horizon: The time frame of our forecast is relatively short, giving less time for a situation to develop into a PHEIC.\n",
            "\n",
            "Balancing these factors, I agree with Forecaster C that although there are reasons for concern, the evidence currently leans toward a lower chance of a PHEIC declaration for avian influenza in humans within this timeframe. Temporary upsurges in cases have happened without escalating to a PHEIC status. The fact that no sustained human-to-human transmission has been reported so far is highly relevant, as this is crucial for a pandemic level spread.\n",
            "\n",
            "However, the new evidence of the virus now affecting cattle - a livestock which has more frequent human contact - cannot be ignored. This represents a new variable and potentially increases the risk. Utilizing the base rate of previous PHEIC declarations and noting that even major outbreaks like H5N1 have not been classified as such, this currently seems less likely unless significant changes like a virus mutation or a sudden surge in human-to-human transmission occur. \n",
            "\n",
            "Taking these factors and the other forecasters' predictions into account, I would adjust the forecast slightly from Forecaster C and put the probability at around 12%.\n",
            "\n",
            "Final Answer: Probability: 12%, 0-100.\n",
            "\n",
            "FINAL WEIGHTED FORECAST:\n",
            "16.8%\n",
            "\n",
            "Overall cost was: $0.071395\n",
            "\n",
            "################ NEXT QUESTION #################\n",
            "\n",
            "Finished forecasting on 1 questions.\n"
          ]
        }
      ],
      "source": [
        "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "client = OpenAI()\n",
        "model = OPEN_AI_MODEL\n",
        "ENABLE_PERPLEXITY_RESEARCH = False  # Previously this could be set to True to get and use pre-computed Perplexity research results for the question, set to False otherwise.\n",
        "# However, Metaculus no longer supports pre-computed Perplexity research, so it has been permanently set to False here to skip over that setp.\n",
        "\n",
        "prompt_templates = [prompt_template_v1 + PROMPT_TEMPLATE, prompt_template_v2 + PROMPT_TEMPLATE, prompt_template_v3 + PROMPT_TEMPLATE]\n",
        "\n",
        "forecasted_count = 0\n",
        "\n",
        "for question_to_forecast_dict in yield_all_questions():\n",
        "  if forecasted_count >= MAX_QUESTIONS_TO_FORECAST:\n",
        "    break\n",
        "  if QUESTION_IDS_TO_FORECAST is not None and question_to_forecast_dict[\"id\"] not in QUESTION_IDS_TO_FORECAST:\n",
        "    continue\n",
        "\n",
        "  print(\"Now Forecasting Question:\")\n",
        "  print(question_to_forecast_dict[\"id\"], question_to_forecast_dict[\"title\"])\n",
        "  print(\"\")\n",
        "\n",
        "  #define perplexity research to use\n",
        "  perplexity_total_cost = \"N/A\"\n",
        "\n",
        "  #if ENABLE_PERPLEXITY_RESEARCH:\n",
        "  #  summary_report = get_perplexity_research(question_to_forecast[\"id\"])\n",
        "  #else:\n",
        "  #  #summary_report = \"No results found, please use your own knowledge and judgement to forecast\"\n",
        "  #  summary_report = \"\"\n",
        "  summary_report = \"\" # ?\n",
        "\n",
        "  # set summary_report to the perplexity recent search if enabled\n",
        "  if USE_PERPLEXITY_RECENT:\n",
        "    print(\"Getting Perplexity recent data...\")\n",
        "    print (\"\")\n",
        "    #print(\"run_llm(...):\")\n",
        "    #print(\"today\", today)\n",
        "    #print(\"client\", client)\n",
        "    #print(\"question_to_forecast_dict\", question_to_forecast_dict)\n",
        "    #print(\"prompt_template_get_perplexity_question\", prompt_template_get_perplexity_question)\n",
        "    #print(\"summary_report\", summary_report)\n",
        "    #print(\"model\", model)\n",
        "\n",
        "    #get prompt completion for use with perplexity\n",
        "    probability, perplexity_recent_prompt_completion, completion_input_cost, completion_output_cost, completion_total_cost = run_llm(today, client, question_to_forecast_dict, prompt_template_get_perplexity_question, summary_report, model, looking_for_probability=False)\n",
        "    #print(\"perplexity_recent_prompt_completion\", perplexity_recent_prompt_completion)\n",
        "    #print(\"completion_input_cost\", completion_input_cost)\n",
        "    #print(\"completion_output_cost\", completion_output_cost)\n",
        "    #print(\"completion_total_cost\", completion_total_cost)\n",
        "    #print(\"\")\n",
        "\n",
        "    perplexity_recent_prompt = \"What is the most recent news available and prior occurrences related to \" + perplexity_recent_prompt_completion\n",
        "\n",
        "    print(f\"The completed question posed to perplexity reads: {perplexity_recent_prompt}\")\n",
        "    #get recent news from perplexity\n",
        "    #print(\"call_perplexity(...)\")\n",
        "    perplexity_content, perplexity_cost = call_perplexity(perplexity_recent_prompt, perplexity_api_key)\n",
        "\n",
        "    summary_report = perplexity_content\n",
        "    perplexity_total_cost = completion_total_cost + perplexity_cost\n",
        "\n",
        "  # need to iterate through prompts here\n",
        "  all_forecasts = []\n",
        "  overall_cost = 0\n",
        "\n",
        "  i = 0\n",
        "  for prompt_template in prompt_templates:\n",
        "    i+=1\n",
        "    print(\"Running initial prompt %s\" % i)\n",
        "    #print(\"run_llm(...)\")\n",
        "    probability, gpt_text, input_cost, output_cost, total_cost = run_llm(today, client, question_to_forecast_dict, prompt_template, summary_report, model)\n",
        "    all_forecasts.append((probability, gpt_text, input_cost, output_cost, total_cost))\n",
        "    overall_cost += total_cost\n",
        "    print(f\"Output Reasoning:\")\n",
        "    print(gpt_text)\n",
        "    print(\"\")\n",
        "    print(\"Extracted probability percentage value (0-100): %s\" % probability)\n",
        "    #print(f\"Input cost: ${input_cost}\")\n",
        "    #print(f\"Output cost: ${output_cost}\")\n",
        "    #print(f\"Total cost: ${total_cost}\")\n",
        "    #print(f\"Perplexity search costs (including LLM prompt completion): ${completion_total_cost + perplexity_cost}\")\n",
        "    print(\"\")\n",
        "    print(\"~~~~ NEXT PROMPT ~~~~\")\n",
        "    print(\"\")\n",
        "\n",
        "  final_prompt_part2_dict = {\n",
        "      \"forecaster1\": all_forecasts[0][1],\n",
        "      \"forecaster2\": all_forecasts[1][1],\n",
        "      \"forecaster3\": all_forecasts[2][1],\n",
        "  }\n",
        "\n",
        "  formatted_final_prompt_part2 = replace_keys(final_prompt_part2, final_prompt_part2_dict)\n",
        "\n",
        "  print(\"+++++++++++ FINAL PROMPT (4) +++++++++++++++++\")\n",
        "\n",
        "  final_prompt_template = final_prompt_part1 + PROMPT_TEMPLATE + formatted_final_prompt_part2\n",
        "\n",
        "  print(\"Running final prompt...\")\n",
        "\n",
        "  probability, gpt_text, input_cost, output_cost, total_cost = run_llm(today, client, question_to_forecast_dict, final_prompt_template, summary_report, model)\n",
        "\n",
        "  print(\"\")\n",
        "  print(gpt_text)\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"Final prompt's individual (non-weighted) extracted probability percentage value (0-100): %s\" % probability)\n",
        "  print(\"\")\n",
        "\n",
        "  forecaster1_weight = 0.2\n",
        "  forecaster2_weight = 0.2\n",
        "  forecaster3_weight = 0.2\n",
        "  forecaster4_weight = 0.4\n",
        "\n",
        "  weighted_forecast = forecaster1_weight*float(all_forecasts[0][0]) + forecaster2_weight*float(all_forecasts[1][0]) + forecaster3_weight*float(all_forecasts[2][0]) + forecaster4_weight*float(probability)\n",
        "  weighted_forecast = round(weighted_forecast,1)\n",
        "  overall_cost = overall_cost + total_cost\n",
        "\n",
        "  #create summary strings for comments:\n",
        "  header_string = f\"\"\"\n",
        "  *This forecast is produced from several prompts initially making forecasts, then a summary forecaster looks over all the previous forecasts and rationales and assess them for level of convincingness before giving its own forecast.  Then a weighted forecast is produced by combining all the inidividual and summary forecasts, weighted based on the initial forecasters' reported confidence and an independently assessed level of rationale strength.  The individual forecasts are reasoned based on knowledge stored inside the latest OpenAI GPT models, supplemented with recent information from targeted Perplexity search results.*\n",
        "\n",
        "  * *Main LLM Model used: {model}*\n",
        "  * *Weighted formula: ({forecaster1_weight})(Forecaster A) + ({forecaster2_weight})(Forecaster B) + ({forecaster3_weight})(Forecaster C) + ({forecaster4_weight})(Summary Forecaster)*\n",
        "  * *Estimated cost of model calls based on tokens (may be incorrect due to differing token costs based on model used): ${round(overall_cost,3)}*\n",
        "  * *** FINAL WEIGHTED FORECAST: {weighted_forecast}%***\n",
        "\n",
        "  ---\n",
        "\n",
        "  \"\"\"\n",
        "  print('Rationale to submit:')\n",
        "  print(\"\")\n",
        "  print(header_string)\n",
        "  print(\"\")\n",
        "\n",
        "  forecasted_count += 1\n",
        "  if SUBMIT_FORECASTS and weighted_forecast is not None:\n",
        "    predict(question_to_forecast_dict[\"id\"], float(weighted_forecast))\n",
        "    comment(question_to_forecast_dict[\"id\"], header_string + \"PERPLEXITY\\n\\n\" + summary_report + \"\\n\\n---\\n\\n\" + \"GPT\\n\\n\" + gpt_text)\n",
        "\n",
        "  print(f\"Output Reasoning:\")\n",
        "  print(gpt_text)\n",
        "  print(\"\")\n",
        "  print(\"FINAL WEIGHTED FORECAST:\")\n",
        "  print(f\"{weighted_forecast}%\")\n",
        "  print(\"\")\n",
        "  print(f\"Overall cost was: ${overall_cost}\")\n",
        "  print(\"\")\n",
        "  print(\"################ NEXT QUESTION #################\")\n",
        "  print(\"\")\n",
        "\n",
        "print(\"Finished forecasting on %s questions.\" % forecasted_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qfSjn0L_8I3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}